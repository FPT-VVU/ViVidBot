{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/bin/huggingface-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/huggingface_hub/commands/huggingface_cli.py\", line 52, in main\n",
      "    service.run()\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/huggingface_hub/commands/user.py\", line 98, in run\n",
      "    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 111, in login\n",
      "    _login(token, add_to_git_credential=add_to_git_credential, write_permission=write_permission)\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 307, in _login\n",
      "    raise ValueError(\"Invalid token passed!\")\n",
      "ValueError: Invalid token passed!\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33df8f4e92bf4490a0b9d75be2e23349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a802c8722db14e0491eee73f467a1e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\n",
    "  \"5CD-AI/Viet-OCR-VQA\",\n",
    "  split=\"train\",\n",
    "  streaming=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from vividbot.data.processor.huggingface import HuggingFaceProcessor\n",
    "\n",
    "hf_processor = HuggingFaceProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 43226.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 40554.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 42777.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 46916.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 51724.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 49286.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 48461.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 46410.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 49660.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:08, 22.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:05, 34.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:10, 19.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:13, 14.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:06, 31.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:08, 23.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:07, 26.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:06, 28.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:07, 26.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:11, 17.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:08, 23.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:15, 12.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:06, 29.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:07, 26.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:07, 25.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:08, 22.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:09, 20.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:06, 28.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:08, 22.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:06, 31.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:14, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:08, 24.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:08, 23.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:07, 27.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:11, 17.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:10, 18.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:08, 22.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:07, 26.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:08, 24.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:08, 22.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:07, 28.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:09, 21.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:11, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:12, 15.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:06, 30.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:07, 25.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:09, 21.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:05, 34.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:08, 22.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:14, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 8117983d-c2cd-41bd-ba38-72788436fdb3)')' thrown while requesting GET https://huggingface.co/datasets/5CD-AI/Viet-OCR-VQA/resolve/03af4838eecf2902bb7af82ecd0a43a845c101a5/data/train-00004-of-00131.parquet\n",
      "Retrying in 1s [Retry 1/5].\n",
      "200it [00:11, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:08, 22.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:11, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:10, 19.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 714b7108-7599-46b9-b5d9-1584f3fba188)')' thrown while requesting GET https://huggingface.co/datasets/5CD-AI/Viet-OCR-VQA/resolve/03af4838eecf2902bb7af82ecd0a43a845c101a5/data/train-00005-of-00131.parquet\n",
      "Retrying in 1s [Retry 1/5].\n",
      "200it [00:06, 32.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:07, 26.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 2df47460-5c49-4b9c-b281-4f9594377930)')' thrown while requesting GET https://huggingface.co/datasets/5CD-AI/Viet-OCR-VQA/resolve/03af4838eecf2902bb7af82ecd0a43a845c101a5/data/train-00002-of-00131.parquet\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: b1f0e089-93ab-4401-a9a7-3778d2fcbafc)')' thrown while requesting GET https://huggingface.co/datasets/5CD-AI/Viet-OCR-VQA/resolve/03af4838eecf2902bb7af82ecd0a43a845c101a5/data/train-00003-of-00131.parquet\n",
      "Retrying in 1s [Retry 1/5].\n",
      "200it [00:07, 27.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:07, 25.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:09, 21.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:08, 23.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:09, 20.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: f352fb9a-6368-4565-91c8-af9aeb01c149)')' thrown while requesting GET https://huggingface.co/datasets/5CD-AI/Viet-OCR-VQA/resolve/03af4838eecf2902bb7af82ecd0a43a845c101a5/data/train-00003-of-00131.parquet\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: c3e17a15-14f7-4e4c-b51a-154dca0ed875)')' thrown while requesting GET https://huggingface.co/datasets/5CD-AI/Viet-OCR-VQA/resolve/03af4838eecf2902bb7af82ecd0a43a845c101a5/data/train-00008-of-00131.parquet\n",
      "Retrying in 1s [Retry 1/5].\n",
      "200it [00:10, 18.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 136\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m count \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m62000\u001b[39m:\n\u001b[1;32m    135\u001b[0m   \u001b[38;5;28mprint\u001b[39m(count)\n\u001b[0;32m--> 136\u001b[0m   batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m   process(batch)\n\u001b[1;32m    138\u001b[0m   count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/iterable_dataset.py:1389\u001b[0m, in \u001b[0;36mIterableDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1386\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m formatter\u001b[38;5;241m.\u001b[39mformat_row(pa_table)\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1389\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, example \u001b[38;5;129;01min\u001b[39;00m ex_iterable:\n\u001b[1;32m   1390\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures:\n\u001b[1;32m   1391\u001b[0m         \u001b[38;5;66;03m# `IterableDataset` automatically fills missing columns with None.\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m         \u001b[38;5;66;03m# This is done with `_apply_feature_types_on_example`.\u001b[39;00m\n\u001b[1;32m   1393\u001b[0m         example \u001b[38;5;241m=\u001b[39m _apply_feature_types_on_example(\n\u001b[1;32m   1394\u001b[0m             example, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures, token_per_repo_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token_per_repo_id\n\u001b[1;32m   1395\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/iterable_dataset.py:1044\u001b[0m, in \u001b[0;36mTakeExamplesIterable.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1044\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m islice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mex_iterable, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/iterable_dataset.py:1025\u001b[0m, in \u001b[0;36mSkipExamplesIterable.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1025\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m islice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mex_iterable, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/iterable_dataset.py:282\u001b[0m, in \u001b[0;36mArrowExamplesIterable.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    281\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m PythonFormatter()\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, pa_table \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_tables_fn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs):\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m pa_subtable \u001b[38;5;129;01min\u001b[39;00m pa_table\u001b[38;5;241m.\u001b[39mto_reader(max_chunksize\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mARROW_READER_BATCH_SIZE_IN_DATASET_ITER):\n\u001b[1;32m    284\u001b[0m             formatted_batch \u001b[38;5;241m=\u001b[39m formatter\u001b[38;5;241m.\u001b[39mformat_batch(pa_subtable)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/packaged_modules/parquet/parquet.py:93\u001b[0m, in \u001b[0;36mParquet._generate_tables\u001b[0;34m(self, files)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, record_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m     91\u001b[0m         parquet_file\u001b[38;5;241m.\u001b[39miter_batches(batch_size\u001b[38;5;241m=\u001b[39mbatch_size, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m     92\u001b[0m     ):\n\u001b[0;32m---> 93\u001b[0m         pa_table \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrecord_batch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;66;03m# Uncomment for debugging (will print the Arrow table size and elements)\u001b[39;00m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;66;03m# logger.warning(f\"pa_table: {pa_table} num rows: {pa_table.num_rows}\")\u001b[39;00m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;66;03m# logger.warning('\\n'.join(str(pa_table.slice(i, 1).to_pydict()) for i in range(pa_table.num_rows)))\u001b[39;00m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cast_table(pa_table)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "_LABEL_QUESTIONS = [\n",
    "  \"Hình này nói về điều gì?\",\n",
    "  \"Bạn mô tả được gì từ hình ảnh này?\",\n",
    "  \"Hình ảnh này thể hiện điều gì?\",\n",
    "  \"Nội dung chính của bức ảnh này là gì?\",\n",
    "  \"Chủ đề chính của bức ảnh này là gì?\",\n",
    "  \"Bạn có thể giải thích ý nghĩa của hình ảnh này không?\",\n",
    "  \"Hình ảnh này đang truyền tải thông điệp gì?\",\n",
    "  \"Bạn có thể tóm tắt nội dung của hình ảnh này không?\",\n",
    "  \"Bạn có thể mô tả về hình ảnh này không?\",\n",
    "]\n",
    "\n",
    "hf_processor = HuggingFaceProcessor()\n",
    "\n",
    "\n",
    "def get_random_label_question(id: Optional[int]) -> str:\n",
    "  if id:\n",
    "    return _LABEL_QUESTIONS[id % len(_LABEL_QUESTIONS)]\n",
    "  else:\n",
    "    return np.random.choice(_LABEL_QUESTIONS)\n",
    "\n",
    "\n",
    "DATA_NAME = \"viet-ocr-vqa\"\n",
    "DATA_NAME_ALT = DATA_NAME.replace(\"-\", \"_\")\n",
    "\n",
    "os.makedirs(f\"{Path.home()}/data/{DATA_NAME}\", exist_ok=True)\n",
    "os.makedirs(f\"{Path.home()}/data/{DATA_NAME}/images\", exist_ok=True)\n",
    "\n",
    "count = 0\n",
    "\n",
    "\n",
    "def convert_message(message: dict):\n",
    "  role = message[\"role\"]\n",
    "  content = message[\"content\"]\n",
    "\n",
    "  return {\"from\": \"human\" if role == \"user\" else \"gpt\", \"value\": content}\n",
    "\n",
    "\n",
    "def process(batch: list):\n",
    "  description_data = []\n",
    "  conversation_data = []\n",
    "\n",
    "  for i, data in tqdm(enumerate(batch)):\n",
    "    image = data[\"image\"]\n",
    "    conversations = data[\"conversations\"]\n",
    "    description = data[\"description\"]\n",
    "    id = data[\"id\"]\n",
    "\n",
    "    if not image.format:\n",
    "      img_exts = [\"png\", \"jpg\"]\n",
    "    else:\n",
    "      img_exts = [image.format.lower()]\n",
    "\n",
    "    for img_ext in img_exts:\n",
    "      try:\n",
    "        # save image\n",
    "        if not os.path.exists(f\"{Path.home()}/data/{DATA_NAME}/images/{id}.{img_ext}\"):\n",
    "          image.save(f\"{Path.home()}/data/{DATA_NAME}/images/{id}.{img_ext}\")\n",
    "        conversations = [convert_message(m) for m in conversations][:10]\n",
    "        if \"<image>\" not in conversations[0][\"value\"]:\n",
    "          conversations[0][\"value\"] = f\"<image>\\n{conversations[0]['value']}\"\n",
    "\n",
    "        conversation_data.append(\n",
    "          {\n",
    "            \"id\": id,\n",
    "            \"image\": f\"images/{id}.{img_ext}\",\n",
    "            \"conversations\": conversations,\n",
    "            \"path\": f\"Vividbot/{DATA_NAME}/images\",\n",
    "          }\n",
    "        )\n",
    "        if i % int(round(62000 * 0.005)) == 0:\n",
    "          conversation_data.append(\n",
    "            {\n",
    "              \"id\": id,\n",
    "              \"image\": f\"images/{id}.{img_ext}\",\n",
    "              \"conversations\": [\n",
    "                {\n",
    "                  \"from\": \"human\",\n",
    "                  \"value\": f\"<image>\\n{get_random_label_question(id=i)}\"\n",
    "                  if i % 2 == 0\n",
    "                  else f\"{get_random_label_question(id=i)}\\n<image>\",\n",
    "                },\n",
    "                {\"from\": \"gpt\", \"value\": description},\n",
    "              ],\n",
    "              \"path\": f\"Vividbot/{DATA_NAME}/images\",\n",
    "            }\n",
    "          )\n",
    "\n",
    "        description_data.append(\n",
    "          {\n",
    "            \"id\": id,\n",
    "            \"image\": f\"images/{id}.{img_ext}\",\n",
    "            \"conversations\": [\n",
    "              {\n",
    "                \"from\": \"human\",\n",
    "                \"value\": f\"<image>\\n{get_random_label_question(id=i)}\"\n",
    "                if i % 2 == 0\n",
    "                else f\"{get_random_label_question(id=i)}\\n<image>\",\n",
    "              },\n",
    "              {\"from\": \"gpt\", \"value\": description},\n",
    "            ],\n",
    "            \"path\": f\"Vividbot/{DATA_NAME}/images\",\n",
    "          }\n",
    "        )\n",
    "        break\n",
    "      except Exception:\n",
    "        pass\n",
    "\n",
    "  # return conversation_data, description_data\n",
    "  # return {\n",
    "  #   \"conversation\": conversation_data,\n",
    "  #   \"description\": description_data,\n",
    "  # }\n",
    "  with open(f\"{Path.home()}/data/{DATA_NAME}/conversation.jsonl\", \"a\") as f:\n",
    "    for d in conversation_data:\n",
    "      f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "  with open(f\"{Path.home()}/data/{DATA_NAME}/description.jsonl\", \"a\") as f:\n",
    "    for d in description_data:\n",
    "      f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "\n",
    "disable_progress_bar()\n",
    "\n",
    "# ds_batched = ds.map(process, batched=True, batch_size=8)\n",
    "count = 0\n",
    "\n",
    "\n",
    "while count < 62000:\n",
    "  print(count)\n",
    "  batch = list(ds.skip(count).take(200))\n",
    "  process(batch)\n",
    "  count += 200\n",
    "\n",
    "  del batch\n",
    "\n",
    "# for batch in it:\n",
    "#   if count > 62000:\n",
    "#     break\n",
    "\n",
    "#   process(batch)\n",
    "#   count += 200\n",
    "\n",
    "#   it = next(it)\n",
    "\n",
    "# with open(f\"{Path.home()}/data/{DATA_NAME}/conversation.jsonl\", \"a\") as f:\n",
    "#   for d in data[\"conversation\"]:\n",
    "#     f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# with open(f\"{Path.home()}/data/{DATA_NAME}/description.jsonl\", \"a\") as f:\n",
    "#   for d in data[\"description\"]:\n",
    "#     f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_description_data = [\n",
    "  json.loads(line)\n",
    "  for line in open(f\"{Path.home()}/data/{DATA_NAME}/description.jsonl\", \"r\")\n",
    "]\n",
    "\n",
    "processed_conversation_data = [\n",
    "  json.loads(line)\n",
    "  for line in open(f\"{Path.home()}/data/{DATA_NAME}/conversation.jsonl\", \"r\")\n",
    "]\n",
    "\n",
    "pretrain_data = processed_description_data\n",
    "pretrain_data = sorted(pretrain_data, key=lambda x: x[\"id\"])\n",
    "\n",
    "finetune_data = processed_conversation_data\n",
    "finetune_data = sorted(finetune_data, key=lambda x: x[\"id\"])\n",
    "\n",
    "with open(f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}_pretrain.json\", \"w\") as f:\n",
    "  f.write(json.dumps(pretrain_data, ensure_ascii=False, indent=2))\n",
    "\n",
    "with open(f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}.json\", \"w\") as f:\n",
    "  f.write(json.dumps(finetune_data, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12200, 12261)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pretrain_data), len(finetune_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10086"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_NAME = \"viet-ocr-vqa\"\n",
    "DATA_NAME_ALT = DATA_NAME.replace(\"-\", \"_\")\n",
    "\n",
    "pretrain_data = json.loads(\n",
    "  open(f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}_pretrain.json\", \"r\").read()\n",
    ")\n",
    "print(len(pretrain_data))\n",
    "# filter out conversation[1][\"value\"] split by space longer than 200\n",
    "pretrain_data = [\n",
    "  d for d in pretrain_data if len(d[\"conversations\"][1][\"value\"].split(\" \")) <= 200\n",
    "]\n",
    "len(pretrain_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}_pretrain.json\", \"w\") as f:\n",
    "  f.write(json.dumps(pretrain_data, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ae2023f5e84559bf526ba36582887b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "viet_ocr_vqa_pretrain.json:   0%|          | 0.00/10.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    }
   ],
   "source": [
    "# hf_processor.zip_and_upload_dir(\n",
    "#   dir_path=f\"{Path.home()}/data/{DATA_NAME}/images\",\n",
    "#   repo_id=f\"Vividbot/{DATA_NAME}\",\n",
    "#   path_in_repo=\"images/images.zip\",\n",
    "#   repo_type=\"dataset\",\n",
    "#   overwrite=True,\n",
    "# )\n",
    "\n",
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}_pretrain.json\",\n",
    "  repo_id=f\"Vividbot/{DATA_NAME}\",\n",
    "  path_in_repo=f\"{DATA_NAME_ALT}_pretrain.json\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True,\n",
    ")\n",
    "\n",
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}.json\",\n",
    "  repo_id=f\"Vividbot/{DATA_NAME}\",\n",
    "  path_in_repo=f\"{DATA_NAME_ALT}.json\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True,\n",
    ")\n",
    "\n",
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/{DATA_NAME}/description.jsonl\",\n",
    "  repo_id=f\"Vividbot/{DATA_NAME}\",\n",
    "  path_in_repo=\"description.jsonl\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True,\n",
    ")\n",
    "\n",
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/{DATA_NAME}/conversation.jsonl\",\n",
    "  repo_id=f\"Vividbot/{DATA_NAME}\",\n",
    "  path_in_repo=\"conversation.jsonl\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vividbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
