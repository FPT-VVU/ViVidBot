{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/ct-minhvu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ct-minhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|██████████| 6.09k/6.09k [00:00<00:00, 42.3MB/s]\n",
      "Downloading data: 100%|██████████| 34/34 [10:33<00:00, 18.63s/files]\n",
      "Generating train split: 100%|██████████| 64765/64765 [05:11<00:00, 207.98 examples/s] \n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"5CD-AI/Viet-Doc-VQA-II\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vividbot.data.processor.huggingface import HuggingFaceProcessor\n",
    "import os\n",
    "from typing import Optional\n",
    "import PIL\n",
    "import numpy as np\n",
    "from openai import images\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "hf_processor = HuggingFaceProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64765"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.WebPImagePlugin.WebPImageFile"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds[0]['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 64759,\n",
       " 'image': <PIL.WebPImagePlugin.WebPImageFile image mode=RGB size=1140x601>,\n",
       " 'description': 'Bức ảnh hiển thị một đoạn văn bản tiếng Việt được viết theo kiểu chữ in, với phông chữ đơn giản và kích thước chữ vừa phải. Văn bản được trình bày theo dạng khối, không có bất kỳ hình ảnh hay biểu đồ nào đi kèm. Nội dung văn bản tập trung vào việc giải thích vai trò của các hoạt động học tập theo nhóm trong việc phát triển các phẩm chất như tinh thần lao động, tinh thần trách nhiệm, ý thức chủ động và bồi dưỡng sự tự tin, hứng thú trong việc học, đồng thời phát triển các năng lực như năng lực giao tiếp và hợp tác, năng lực giải quyết vấn đề và sáng tạo. Ngoài ra, văn bản còn đề cập đến vai trò của sách giáo khoa Toán 2 trong việc góp phần hình thành và phát triển năng lực tính toán, năng lực ngôn ngữ và các năng lực đặc thù khác.',\n",
       " 'conversations': [{'role': 'user',\n",
       "   'content': 'Theo văn bản, việc học tập theo nhóm mang lại lợi ích gì cho học sinh?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Học tập theo nhóm giúp học sinh phát triển các phẩm chất như tinh thần lao động, tinh thần trách nhiệm, ý thức chủ động và bồi dưỡng sự tự tin, hứng thú trong việc học. Đồng thời, nó cũng giúp phát triển các năng lực như năng lực giao tiếp và hợp tác, năng lực giải quyết vấn đề và sáng tạo.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Sách giáo khoa Toán 2 có vai trò gì trong việc phát triển năng lực của học sinh?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Sách giáo khoa Toán 2 góp phần hình thành và phát triển năng lực tính toán, năng lực ngôn ngữ và các năng lực đặc thù khác. Nó được thiết kế với những ưu thế nổi trội, thông qua cấu trúc mở, linh hoạt, hệ thống bài tập, ví dụ, hoạt động phong phú, đa dạng, sẽ đảm bảo cho học sinh có thể vừa rèn luyện kỹ năng tính toán, ước lượng, vừa giúp hình thành và phát triển các thành tố của năng lực toán học như năng lực tự duy, lập luận, năng lực mô hình hóa, năng lực giao tiếp...'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Văn bản đề cập đến những năng lực đặc thù nào được phát triển qua việc học Toán?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Văn bản đề cập đến các năng lực đặc thù như năng lực tính toán, năng lực ngôn ngữ, năng lực tự duy, lập luận, năng lực mô hình hóa, năng lực giao tiếp, năng lực thẩm mỹ.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Theo văn bản, sách giáo khoa Toán 2 được thiết kế như thế nào?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Sách giáo khoa Toán 2 được thiết kế với những ưu thế nổi trội, thông qua cấu trúc mở, linh hoạt, hệ thống bài tập, ví dụ, hoạt động phong phú, đa dạng, sẽ đảm bảo cho học sinh có thể vừa rèn luyện kỹ năng tính toán, ước lượng, vừa giúp hình thành và phát triển các thành tố của năng lực toán học.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Mục tiêu cuối cùng mà sách giáo khoa Toán 2 hướng đến là gì?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Sách giáo khoa Toán 2 góp phần phát triển năng lực ngôn ngữ, năng lực thẩm mỹ cho học sinh, giúp học sinh có được tầm nhìn rộng mở đối với thế giới xung quanh.'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28601"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_conversation_data = load_dataset(\"json\", data_files=f\"{Path.home()}/data/viet-doc-vqa-2/conversation_64k.jsonl\", split=\"train\")\n",
    "\n",
    "len(processed_conversation_data[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:16, 11.77it/s]\n",
      "200it [00:16, 11.99it/s]\n",
      "200it [00:18, 11.09it/s]\n",
      "200it [00:14, 13.38it/s]\n",
      "200it [00:15, 12.65it/s]\n",
      "200it [00:16, 12.22it/s]\n",
      "200it [00:14, 13.55it/s]\n",
      "200it [00:14, 13.60it/s]\n",
      "200it [00:16, 12.47it/s]\n",
      "200it [00:14, 13.46it/s]\n",
      "200it [00:14, 13.53it/s]\n",
      "200it [00:15, 13.10it/s]\n",
      "200it [00:14, 13.95it/s]\n",
      "200it [00:15, 13.15it/s]\n",
      "200it [00:14, 13.81it/s]\n",
      "200it [00:15, 13.11it/s]\n",
      "200it [00:15, 13.19it/s]\n",
      "200it [00:13, 14.88it/s]\n",
      "200it [00:15, 13.15it/s]\n",
      "200it [00:14, 13.86it/s]\n",
      "200it [00:15, 13.08it/s]\n",
      "200it [00:14, 13.39it/s]\n",
      "200it [00:13, 14.84it/s]\n",
      "200it [00:16, 12.17it/s]\n",
      "200it [00:13, 14.33it/s]\n",
      "200it [00:15, 13.10it/s]\n",
      "200it [00:17, 11.59it/s]\n",
      "200it [00:14, 14.05it/s]\n",
      "200it [00:14, 13.39it/s]\n",
      "200it [00:16, 11.96it/s]\n",
      "200it [00:14, 14.19it/s]\n",
      "200it [00:15, 13.26it/s]\n",
      "200it [00:13, 14.84it/s]\n",
      "200it [00:16, 12.40it/s]\n",
      "200it [00:16, 12.29it/s]\n",
      "200it [00:13, 15.21it/s]\n",
      "200it [00:15, 12.81it/s]\n",
      "200it [00:15, 13.03it/s]\n",
      "200it [00:12, 15.44it/s]\n",
      "200it [00:15, 13.04it/s]\n",
      "200it [00:13, 14.64it/s]\n",
      "200it [00:14, 13.49it/s]\n",
      "200it [00:14, 13.35it/s]\n",
      "200it [00:14, 13.92it/s]\n",
      "200it [00:15, 13.06it/s]\n",
      "200it [00:14, 13.56it/s]\n",
      "200it [00:14, 13.84it/s]\n",
      "200it [00:16, 12.32it/s]\n",
      "200it [00:13, 14.70it/s]\n",
      "200it [00:15, 12.62it/s]\n",
      "200it [00:15, 12.78it/s]\n",
      "200it [00:14, 14.17it/s]\n",
      "200it [00:16, 12.48it/s]\n",
      "200it [00:15, 12.98it/s]\n",
      "200it [00:14, 14.08it/s]\n",
      "200it [00:15, 12.78it/s]\n",
      "200it [00:15, 12.56it/s]\n",
      "200it [00:13, 15.16it/s]\n",
      "200it [00:15, 12.50it/s]\n",
      "200it [00:16, 11.92it/s]\n",
      "200it [00:14, 14.09it/s]\n",
      "200it [00:14, 13.35it/s]\n",
      "200it [00:17, 11.60it/s]\n",
      "200it [00:13, 14.37it/s]\n",
      "200it [00:14, 13.47it/s]\n",
      "200it [00:14, 14.24it/s]\n",
      "200it [00:17, 11.50it/s]\n",
      "200it [00:14, 13.73it/s]\n",
      "200it [00:14, 13.60it/s]\n",
      "200it [00:17, 11.60it/s]\n",
      "200it [00:15, 12.52it/s]\n",
      "200it [00:15, 12.78it/s]\n",
      "200it [00:18, 10.73it/s]\n",
      "200it [00:15, 12.65it/s]\n",
      "200it [00:13, 14.34it/s]\n",
      "200it [00:14, 14.09it/s]\n",
      "200it [00:13, 14.32it/s]\n",
      "200it [00:17, 11.13it/s]\n",
      "200it [00:14, 14.21it/s]\n",
      "200it [00:12, 15.50it/s]\n",
      "200it [00:14, 13.52it/s]\n",
      "200it [00:13, 14.89it/s]\n",
      "200it [00:14, 14.17it/s]\n",
      "200it [00:15, 12.53it/s]\n",
      "200it [00:13, 14.51it/s]\n",
      "200it [00:14, 14.00it/s]\n",
      "200it [00:16, 12.06it/s]\n",
      "200it [00:13, 14.31it/s]\n",
      "200it [00:13, 14.50it/s]\n",
      "200it [00:16, 12.04it/s]\n",
      "200it [00:15, 13.28it/s]\n",
      "200it [00:15, 12.96it/s]\n",
      "200it [00:16, 12.21it/s]\n",
      "200it [00:15, 13.26it/s]\n",
      "200it [00:15, 13.31it/s]\n",
      "200it [00:16, 12.27it/s]\n",
      "200it [00:14, 13.68it/s]\n",
      "200it [00:14, 13.85it/s]\n",
      "200it [00:15, 12.61it/s]\n",
      "200it [00:14, 13.69it/s]\n",
      "200it [00:16, 11.96it/s]\n",
      "200it [00:15, 13.14it/s]\n",
      "200it [00:15, 13.06it/s]\n",
      "200it [00:15, 13.21it/s]\n",
      "133it [00:10, 12.51it/s]"
     ]
    }
   ],
   "source": [
    "_QUESTIONS = [\n",
    "  \"Hình này nói về điều gì?\",\n",
    "  \"Đây là gì?\",\n",
    "  \"Bạn mô tả được gì từ hình ảnh này?\",\n",
    "  \"Hình ảnh này thể hiện điều gì?\",\n",
    "  \"Nội dung chính của bức ảnh này là gì?\",\n",
    "  \"Bạn nhìn thấy gì trong hình này?\",\n",
    "  \"Hình ảnh này đang minh họa cho điều gì?\",\n",
    "  \"Chủ đề chính của bức ảnh này là gì?\",\n",
    "  \"Bạn có thể giải thích ý nghĩa của hình ảnh này không?\",\n",
    "  \"Hình ảnh này đang cố gắng truyền tải thông điệp gì?\",\n",
    "  \"Những yếu tố chính nào bạn nhận thấy trong hình này?\",\n",
    "  \"Bạn có thể tóm tắt nội dung của hình ảnh này không?\",\n",
    "  \"Hình ảnh này đang kể câu chuyện gì?\",\n",
    "  \"Điểm nổi bật nhất trong bức ảnh này là gì?\",\n",
    "  \"Bạn có thể mô tả ngắn gọn về hình ảnh này không?\",\n",
    "  \"Có những gì đáng chú ý trong hình ảnh này?\",\n",
    "  \"Hãy đặt tựa đề cho bức ảnh này.\",\n",
    "  \"Nếu bạn phải mô tả hình ảnh này bằng một câu, bạn sẽ nói gì?\",\n",
    "  \"Đề xuất một chú thích ngắn gọn cho hình ảnh này.\",\n",
    "]\n",
    "\n",
    "\n",
    "hf_processor = HuggingFaceProcessor()\n",
    "\n",
    "\n",
    "def get_random_question(id: Optional[int]) -> str:\n",
    "  if id:\n",
    "    return _QUESTIONS[id % len(_QUESTIONS)]\n",
    "  else:\n",
    "    return np.random.choice(_QUESTIONS)\n",
    "  \n",
    "\n",
    "\n",
    "processed_conversation_ids = load_dataset(\"json\", data_files=f\"{Path.home()}/data/viet-doc-vqa-2/conversation_64k.jsonl\", split=\"train\")[\"id\"] if os.path.exists(f\"{Path.home()}/data/viet-doc-vqa-2/conversation_64k.jsonl\") else []\n",
    "processed_detail_ids = load_dataset(\"json\", data_files=f\"{Path.home()}/data/viet-doc-vqa-2/detail_64k.jsonl\", split=\"train\")[\"id\"] if os.path.exists(f\"{Path.home()}/data/viet-doc-vqa-2/detail_64k.jsonl\") else []\n",
    "\n",
    "def convert_message(message: dict):\n",
    "  role = message[\"role\"]\n",
    "  content = message[\"content\"]\n",
    "\n",
    "  return {\n",
    "    \"from\": \"human\" if role == \"user\" else \"gpt\",\n",
    "    \"value\": content\n",
    "  }\n",
    "\n",
    "def process(batch: dict):\n",
    "  batch_ids = batch[\"id\"]\n",
    "  batch_images = batch[\"image\"]\n",
    "  batch_descriptions = batch[\"description\"]\n",
    "  batch_conversations = batch[\"conversations\"]\n",
    "\n",
    "  conversation_data = []\n",
    "  detail_data = []\n",
    "\n",
    "  for i, (id, image, description, conversations) in tqdm(enumerate(zip(batch_ids, batch_images, batch_descriptions, batch_conversations))):\n",
    "    if id in processed_conversation_ids and id in processed_detail_ids:\n",
    "      continue\n",
    "\n",
    "    conversations = [convert_message(message) for message in conversations]\n",
    "    if len(conversations) == 0:\n",
    "      continue\n",
    "\n",
    "    if np.random.rand() < 0.5:\n",
    "      conversations[0][\"value\"] = f\"{conversations[0]['value']}\\n<image>\"\n",
    "    else:\n",
    "      conversations[0][\"value\"] = f\"<image>\\n{conversations[0]['value']}\"\n",
    "\n",
    "    img_ext = image.format.lower()\n",
    "\n",
    "    conversation_data.append({\n",
    "      \"id\": id,\n",
    "      \"image\": f\"images/{id}.{img_ext}\",\n",
    "      \"conversations\": conversations\n",
    "    })\n",
    "\n",
    "    detail_data.append({\n",
    "      \"id\": id,\n",
    "      \"image\": f\"images/{id}.{img_ext}\",\n",
    "      \"conversations\": [\n",
    "        {\n",
    "          \"from\" : \"human\",\n",
    "          \"value\": f\"<image>\\n{get_random_question(id=i)}\" if i % 2 == 0 else f\"{get_random_question(id=i)}\\n<image>\"\n",
    "        }, {\n",
    "          \"from\": \"gpt\",\n",
    "          \"value\": description\n",
    "        }\n",
    "      ]\n",
    "    })\n",
    "\n",
    "    # save image\n",
    "    if not os.path.exists(f\"{Path.home()}/data/viet-doc-vqa-2/{id}.{img_ext}\"):\n",
    "      image.save(f\"{Path.home()}/data/viet-doc-vqa-2/images/{id}.{img_ext}\")\n",
    "\n",
    "  with open(f\"{Path.home()}/data/viet-doc-vqa-2/conversation_64k.jsonl\", \"a\") as f:\n",
    "    for d in conversation_data:\n",
    "      f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")\n",
    "      \n",
    "\n",
    "  with open(f\"{Path.home()}/data/viet-doc-vqa-2/detail_64k.jsonl\", \"a\") as f:\n",
    "    for d in detail_data:\n",
    "      f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "disable_progress_bar()\n",
    "\n",
    "ds.map(process, batched=True, batch_size=200, num_proc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51856\n",
      "51856\n"
     ]
    }
   ],
   "source": [
    "processed_conversation_data = open(f\"{Path.home()}/data/viet-doc-vqa-2/conversation_64k.jsonl\").readlines()\n",
    "processed_detail_data = open(f\"{Path.home()}/data/viet-doc-vqa-2/detail_64k.jsonl\").readlines()\n",
    "\n",
    "processed_conversation_data = [json.loads(d) for d in processed_conversation_data]\n",
    "processed_detail_data = [json.loads(d) for d in processed_detail_data]\n",
    "\n",
    "print(len(processed_conversation_data))\n",
    "print(len(processed_detail_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = processed_conversation_data + processed_detail_data\n",
    "\n",
    "combined_data = sorted(combined_data, key=lambda x: x[\"id\"])\n",
    "\n",
    "with open(f\"{Path.home()}/data/viet-doc-vqa-2/viet_doc_vqa_2_128k.jsonl\", \"w\") as f:\n",
    "  for d in combined_data:\n",
    "    f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "with open(f\"{Path.home()}/data/viet-doc-vqa-2/viet_doc_vqa_2_128k_all.json\", \"w\") as f:\n",
    "  f.write(json.dumps(combined_data, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbdt = load_dataset(\"json\", data_files=f\"{Path.home()}/data/viet-doc-vqa-2/viet_doc_vqa_2_128k.jsonl\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in cbdt:\n",
    "  if d[\"image\"].endswith(\"png\"):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbdt2 = json.loads(open(f\"{Path.home()}/data/viet-doc-vqa-2/viet_doc_vqa_2_128k_all.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 11,\n",
       " 'image': 'images/11.jpg',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nTheo đoạn văn bản, Việt Nam đã gia nhập tổ chức nào vào năm nào?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Theo đoạn văn bản, Việt Nam đã gia nhập Tổ chức Thương mại Thế giới (WTO) vào năm 2005. '},\n",
       "  {'from': 'human',\n",
       "   'value': 'Theo đoạn văn bản, Nhà nước có vai trò gì trong việc định hướng hoạt động kinh doanh, quản lý tài chính, luật pháp và chính sách?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Theo đoạn văn bản, Nhà nước đóng vai trò quan trọng trong việc định hướng hoạt động kinh doanh, quản lý tài chính, luật pháp và chính sách. Nhà nước ban hành các chính sách, luật lệ và quy định để điều chỉnh, quản lý và định hướng hoạt động kinh doanh, tài chính, luật pháp và chính sách của các doanh nghiệp và người dân trong nước.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'Theo biểu đồ, xuất khẩu của Việt Nam năm 1992 chiếm bao nhiêu phần trăm?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Theo biểu đồ, xuất khẩu của Việt Nam năm 1992 chiếm khoảng 50,4%.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'Theo biểu đồ, xuất khẩu của Việt Nam năm 2005 chiếm bao nhiêu phần trăm?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Theo biểu đồ, xuất khẩu của Việt Nam năm 2005 chiếm khoảng 46,9%.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'Theo biểu đồ, nhập khẩu của Việt Nam năm nào đạt mức cao nhất?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Theo biểu đồ, nhập khẩu của Việt Nam đạt mức cao nhất vào năm 1999, với tỷ lệ khoảng 50,4%.'}]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbdt2[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "images.zip: 100%|██████████| 4.52G/4.52G [16:17<00:00, 4.62MB/s] \n"
     ]
    }
   ],
   "source": [
    "hf_processor.zip_and_upload_dir(\n",
    "  dir_path=f\"{Path.home()}/data/viet-doc-vqa-2/images\",\n",
    "  repo_id=\"Vividbot/viet-doc-vqa-2\",\n",
    "  path_in_repo=\"images/images.zip\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "viet_doc_vqa_102k.jsonl: 100%|██████████| 193M/193M [00:44<00:00, 4.29MB/s] \n",
      "viet_doc_vqa_102k_all.json: 100%|██████████| 214M/214M [00:52<00:00, 4.08MB/s] \n",
      "conversation_51k.jsonl: 100%|██████████| 123M/123M [00:28<00:00, 4.37MB/s] \n",
      "detail_51k.jsonl: 100%|██████████| 69.3M/69.3M [00:15<00:00, 4.44MB/s]\n"
     ]
    }
   ],
   "source": [
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/viet-doc-vqa-2/viet_doc_vqa_2_128k.jsonl\",\n",
    "  repo_id=\"Vividbot/viet-doc-vqa-2\",\n",
    "  path_in_repo=\"viet_doc_vqa_2_128k.jsonl\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True\n",
    ")\n",
    "\n",
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/viet-doc-vqa-2/viet_doc_vqa_2_128k_all.json\",\n",
    "  repo_id=\"Vividbot/viet-doc-vqa-2\",\n",
    "  path_in_repo=\"viet_doc_vqa_2_128k_all.json\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True\n",
    ")\n",
    "\n",
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/viet-doc-vqa-2/conversation_64k.jsonl\",\n",
    "  repo_id=\"Vividbot/viet-doc-vqa-2\",\n",
    "  path_in_repo=\"conversation_64k.jsonl\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True\n",
    ")\n",
    "\n",
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/viet-doc-vqa-2/detail_64k.jsonl\",\n",
    "  repo_id=\"Vividbot/viet-doc-vqa-2\",\n",
    "  path_in_repo=\"detail_64k.jsonl\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vividbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
