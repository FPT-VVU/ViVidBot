{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/dminhvu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed5af48f9944b5093eb153e95b1fa80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/3.68k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8543919fc7456cb85f00f239eac583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/175M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65845490e6084073a3ff90b40abe1eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/168M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302e88c5b9cf4627b651b67bc750eab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/164M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5912a626f34fbcafdd48190645a083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/161M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00fbd63328664a93b9a2d6ed2a058e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/164M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d02fb5ee134f328ebd0069d4b67e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/168M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590220eab042493ca5b49fe052b8eec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/168M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20022322777a4f02b46a00dcd7959ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8024 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"5CD-AI/Viet-OpenViVQA-gemini-VQA\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from vividbot.data.processor.huggingface import HuggingFaceProcessor\n",
    "\n",
    "hf_processor = HuggingFaceProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8024"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=660x440>,\n",
       " 'description': 'Bức ảnh chụp một chiếc xe bồn màu trắng, có dòng chữ \"HỆ THỐNG THÀNH PHỐ XANH - SẠCH - ĐẸP\" được in trên bồn chứa nước màu xanh dương.  Hai nhân viên y tế mặc đồ bảo hộ màu xanh dương đang đi bộ phía sau xe.  Phía trước xe là một cổng sắt màu đỏ, phía sau xe là một cái cây xanh.  Trời có nắng và bầu trời trong xanh.',\n",
       " 'conversations': [{'role': 'user',\n",
       "   'content': 'Những nhân viên y tế đang mang trang phục gì ?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Những nhân viên y tế đang mang đồ bảo hộ y tế.'},\n",
       "  {'role': 'user', 'content': 'Cái bồn trên xe có màu gì ?'},\n",
       "  {'role': 'assistant', 'content': 'Cái bồn có màu trắng và màu xanh dương.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Có bao nhiêu nhân viên y tế đi phía sau chiếc xe ?'},\n",
       "  {'role': 'assistant', 'content': 'Có hai nhân viên y tế.'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 342.16it/s]\n",
      "200it [00:00, 330.46it/s]\n",
      "200it [00:00, 311.90it/s]\n",
      "200it [00:00, 337.02it/s]\n",
      "200it [00:00, 359.35it/s]\n",
      "200it [00:00, 354.22it/s]\n",
      "200it [00:00, 319.99it/s]\n",
      "200it [00:00, 272.15it/s]\n",
      "200it [00:00, 287.77it/s]\n",
      "200it [00:00, 362.98it/s]\n",
      "200it [00:00, 386.30it/s]\n",
      "200it [00:00, 306.34it/s]\n",
      "200it [00:00, 248.49it/s]\n",
      "200it [00:00, 292.91it/s]\n",
      "200it [00:00, 263.86it/s]\n",
      "200it [00:00, 317.97it/s]\n",
      "200it [00:00, 357.54it/s]\n",
      "200it [00:00, 298.94it/s]\n",
      "200it [00:00, 392.11it/s]\n",
      "200it [00:00, 288.75it/s]\n",
      "200it [00:00, 299.06it/s]\n",
      "200it [00:00, 350.76it/s]\n",
      "200it [00:00, 377.19it/s]\n",
      "200it [00:00, 366.10it/s]\n",
      "200it [00:00, 353.17it/s]\n",
      "200it [00:00, 347.88it/s]\n",
      "200it [00:00, 329.89it/s]\n",
      "200it [00:00, 359.12it/s]\n",
      "200it [00:00, 325.59it/s]\n",
      "200it [00:00, 359.14it/s]\n",
      "200it [00:00, 403.81it/s]\n",
      "200it [00:00, 402.10it/s]\n",
      "200it [00:00, 378.94it/s]\n",
      "200it [00:00, 367.95it/s]\n",
      "200it [00:00, 332.61it/s]\n",
      "200it [00:00, 310.59it/s]\n",
      "200it [00:00, 345.67it/s]\n",
      "200it [00:00, 411.50it/s]\n",
      "75it [00:00, 471.01it/s]\n",
      "74it [00:00, 375.77it/s]\n",
      "200it [00:00, 337.93it/s]\n",
      "75it [00:00, 422.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'image', 'description', 'conversations'],\n",
       "    num_rows: 8024\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_DESCRIPTION_QUESTIONS = [\n",
    "  \"Nội dung của hình ảnh là gì?\",\n",
    "  \"Hãy mô tả hình ảnh này.\",\n",
    "  \"Hãy cho biết nội dung của hình ảnh?\",\n",
    "  \"Trong hình ảnh này có gì?\",\n",
    "  \"Viết một đoạn mô tả về hình ảnh này.\",\n",
    "  \"Bức ảnh này chụp về chủ đề gì?\",\n",
    "  \"Đây là hình ảnh về gì?\",\n",
    "  \"Đây là gì?\",\n",
    "  \"Hình ảnh này là gì?\",\n",
    "  \"Mô tả bức ảnh này.\",\n",
    "]\n",
    "\n",
    "\n",
    "hf_processor = HuggingFaceProcessor()\n",
    "\n",
    "\n",
    "def get_random_description_question(id: Optional[int]) -> str:\n",
    "  if id:\n",
    "    return _DESCRIPTION_QUESTIONS[id % len(_DESCRIPTION_QUESTIONS)]\n",
    "  else:\n",
    "    return np.random.choice(_DESCRIPTION_QUESTIONS)\n",
    "\n",
    "\n",
    "DATA_NAME = \"viet-openvivqa\"\n",
    "DATA_NAME_ALT = DATA_NAME.replace(\"-\", \"_\")\n",
    "SAMPLE_COUNT = round(len(ds) / 1000)\n",
    "\n",
    "os.makedirs(f\"{Path.home()}/data/{DATA_NAME}\", exist_ok=True)\n",
    "os.makedirs(f\"{Path.home()}/data/{DATA_NAME}/images\", exist_ok=True)\n",
    "\n",
    "\n",
    "def convert_message(message: dict):\n",
    "  role = message[\"role\"]\n",
    "  content = message[\"content\"]\n",
    "\n",
    "  return {\"from\": \"human\" if role == \"user\" else \"gpt\", \"value\": content}\n",
    "\n",
    "\n",
    "fails = []\n",
    "\n",
    "\n",
    "def process(batch: dict):\n",
    "  batch_ids = batch[\"id\"]\n",
    "  batch_images = batch[\"image\"]\n",
    "  batch_descriptions = batch[\"description\"]\n",
    "  batch_conversations = batch[\"conversations\"]\n",
    "\n",
    "  conversation_data = []\n",
    "  detail_data = []\n",
    "\n",
    "  for i, (id, image, description, conversations) in tqdm(\n",
    "    enumerate(zip(batch_ids, batch_images, batch_descriptions, batch_conversations))\n",
    "  ):\n",
    "    saved = False\n",
    "    img_exts = [image.format.lower()] if image.format else [\"jpg\", \"png\"]\n",
    "    for img_ext in img_exts:\n",
    "      try:\n",
    "        # save image\n",
    "        if not os.path.exists(f\"{Path.home()}/data/{DATA_NAME}/images/{id}.{img_ext}\"):\n",
    "          image.save(f\"{Path.home()}/data/{DATA_NAME}/images/{id}.{img_ext}\")\n",
    "\n",
    "        conversations = [convert_message(message) for message in conversations][:6]\n",
    "        if len(conversations) == 0:\n",
    "          continue\n",
    "\n",
    "        if np.random.rand() < 0.5:\n",
    "          conversations[0][\"value\"] = f\"{conversations[0]['value']}\\n<image>\"\n",
    "        else:\n",
    "          conversations[0][\"value\"] = f\"<image>\\n{conversations[0]['value']}\"\n",
    "\n",
    "        conversation_data.append(\n",
    "          {\n",
    "            \"id\": id,\n",
    "            \"image\": f\"images/{id}.{img_ext}\",\n",
    "            \"conversations\": conversations,\n",
    "          }\n",
    "        )\n",
    "\n",
    "        detail_data.append(\n",
    "          {\n",
    "            \"id\": id,\n",
    "            \"image\": f\"images/{id}.{img_ext}\",\n",
    "            \"conversations\": [\n",
    "              {\n",
    "                \"from\": \"human\",\n",
    "                \"value\": f\"<image>\\n{get_random_description_question(id=i)}\"\n",
    "                if i % 2 == 0\n",
    "                else f\"{get_random_description_question(id=i)}\\n<image>\",\n",
    "              },\n",
    "              {\"from\": \"gpt\", \"value\": description},\n",
    "            ],\n",
    "          }\n",
    "        )\n",
    "\n",
    "        saved = True\n",
    "        break\n",
    "      except Exception:\n",
    "        continue\n",
    "\n",
    "    if not saved:\n",
    "      print(f\"Failed to save image {id}\")\n",
    "      fails.append(\n",
    "        {\n",
    "          \"id\": id,\n",
    "          \"image\": image,\n",
    "          \"description\": description,\n",
    "          \"conversations\": conversations,\n",
    "        }\n",
    "      )\n",
    "\n",
    "  with open(\n",
    "    f\"{Path.home()}/data/{DATA_NAME}/conversation_{SAMPLE_COUNT}k.jsonl\", \"a\"\n",
    "  ) as f:\n",
    "    for d in conversation_data:\n",
    "      f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "  with open(f\"{Path.home()}/data/{DATA_NAME}/detail_{SAMPLE_COUNT}k.jsonl\", \"a\") as f:\n",
    "    for d in detail_data:\n",
    "      f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "\n",
    "disable_progress_bar()\n",
    "\n",
    "ds.map(process, batched=True, batch_size=200, num_proc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8024\n",
      "8024\n"
     ]
    }
   ],
   "source": [
    "processed_conversation_data = open(\n",
    "  f\"{Path.home()}/data/{DATA_NAME}/conversation_{SAMPLE_COUNT}k.jsonl\"\n",
    ").readlines()\n",
    "processed_detail_data = open(\n",
    "  f\"{Path.home()}/data/{DATA_NAME}/detail_{SAMPLE_COUNT}k.jsonl\"\n",
    ").readlines()\n",
    "\n",
    "processed_conversation_data = [json.loads(d) for d in processed_conversation_data]\n",
    "processed_detail_data = [json.loads(d) for d in processed_detail_data]\n",
    "\n",
    "print(len(processed_conversation_data))\n",
    "print(len(processed_detail_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = processed_detail_data + processed_conversation_data\n",
    "\n",
    "combined_data = sorted(combined_data, key=lambda x: x[\"id\"])\n",
    "combined_data = [{**d, \"path\": f\"Vividbot/{DATA_NAME}/images\"} for d in combined_data]\n",
    "\n",
    "with open(f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}.jsonl\", \"w\") as f:\n",
    "  for d in combined_data:\n",
    "    f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "with open(f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}.json\", \"w\") as f:\n",
    "  f.write(json.dumps(combined_data, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "t = \"KEN COFFEE\\n03 Chế Lan Viên, Quy Nhơn\\n\\nCAFE\\nCafe đen/ cafe đá\\nEspresso/ espresso đá\\nCafe sữa/ cafe sữa đá\\nBạc sỉu đá/ espresso sữa đá\\nTrà gừng nóng\\nTrà lipton đá/ nóng\\nCa cao sữa đá/ nóng\\nSoda chanh\\n\\nNƯỚC ÉP TRÁI CÂY\\nChanh tươi\\nCam vắt\\nỔi ép\\nCa Chua ép\\nCa Đá Lạt\\nNước dừa tươi\\n\\nSỮA - SỮA CHUA\\nSữa chua\\nSữa chua đá\\nSữa chua cafe\\nSữa vinamilk hộp\\nSữa đậu xanh\\n\\nNƯỚC NGỌT\\nSting, Pepsi, Rivive\\n7up, Number one\\nNuti\\nBò Húc\\nKingdang Lavie\\n\\nBÁNH VÀ ĐỒ ĂN VẶT\\nHạt hướng dương\\nHạt dưa\\nMực bento\\nKhoai ga\\n\\n\\n\\nKEN COFFEE\\n03 Chế Lan Viên, Quy Nhơn\\n\\nCAFE\\nCafe đen/ cafe đá\\nEspresso/ espresso đá\\nCafe sữa/ cafe sữa đá\\nBạc sỉu đá/ espresso sữa đá\\nTrà gừng nóng\\nTrà lipton đá/ nóng\\nCa cao sữa đá/ nóng\\nSoda chanh\\n\\nNƯỚC ÉP TRÁI CÂY\\nChanh tươi\\nCam vắt\\nỔi ép\\nCa Chua ép\\nCa Đá Lạt\\nNước dừa tươi\\n\\nSỮA - SỮA CHUA\\nSữa chua\\nSữa chua đá\\nSữa chua cafe\\nSữa vinamilk hộp\\nSữa đậu xanh\\n\\nNƯỚC NGỌT\\nSting, Pepsi, Rivive\\n7up, Number one\\nNuti\\nBò Húc\\nKingdang Lavie\\n\\nBÁNH VÀ ĐỒ ĂN VẶT\\nHạt hướng dương\\nHạt dưa\\nMực bento\\nKhoai ga\\n\"\n",
    "print(len(re.split(r\"[\\n ]+\", t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbdt2 = json.loads(\n",
    "  open(\n",
    "    f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}_{SAMPLE_COUNT*2}k_all.json\"\n",
    "  ).read()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'image': 'images/0.jpeg',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nBài toán yêu cầu chứng minh điều gì ở phần a)?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Phần a) của bài toán yêu cầu chứng minh rằng OPQ là tam giác cân. Lời giải cho phần này dựa vào việc chứng minh tứ giác MBQO là tứ giác nội tiếp, từ đó suy ra hai góc MQQ và MBO bằng nhau (cùng chắn cung MO). Tiếp theo, tương tự với tứ giác MPCO,  ta cũng có hai góc MPO và MCO bằng nhau.  Từ đó suy ra góc MPO bằng góc MQO,  hay tam giác OPQ cân tại O.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'Phần b) của bài toán giải quyết vấn đề gì?  Nêu rõ các bước chứng minh.'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Phần b) của bài toán yêu cầu chứng minh rằng CR bằng HM.  Để chứng minh điều này,  bài toán sử dụng các tam giác đồng dạng.  Cụ thể,  ta có tam giác APR đồng dạng với tam giác ACOH.  Từ đó suy ra tỉ lệ:  PC/RC = CO/OH.  Tiếp theo,  ta có tam giác AMOH đồng dạng với tam giác APOC,  từ đó suy ra tỉ lệ:  MH/HO = PC/OC.  Kết hợp hai tỉ lệ trên,  ta suy ra CR bằng MH.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'Phần c) của bài toán muốn chứng minh điều gì?  Cách giải quyết như thế nào?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Phần c) của bài toán yêu cầu chứng minh rằng tứ giác ACDK là tứ giác nội tiếp.  Để chứng minh điều này,  bài toán sử dụng các tam giác đồng dạng.  Cụ thể,  ta có tam giác AHB đồng dạng với tam giác ACO,  từ đó suy ra tỉ lệ:  AB/BH = AO/CO.  Tiếp theo,  ta có tam giác ABK đồng dạng với tam giác AOD,  từ đó suy ra tỉ lệ:  AB/BK = AO/OD.  Kết hợp hai tỉ lệ trên,  ta suy ra góc AKB bằng góc ADO.  Từ đó,  ta kết luận rằng tứ giác ACDK là tứ giác nội tiếp.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'Phần d) của bài toán giải quyết vấn đề gì?  Nêu rõ các bước chứng minh.'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Phần d) của bài toán yêu cầu chứng minh rằng ABEC là hình thoi.  Để chứng minh điều này,  bài toán sử dụng tính chất của điểm đối xứng.  Cụ thể,  do K là điểm đối xứng với H qua B,  nên KB bằng KH.  Tiếp theo,  do tứ giác ACDK là tứ giác nội tiếp,  nên góc KAB bằng góc KEB.  Kết hợp hai điều trên,  ta suy ra ABEC là hình thoi.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'Hình vẽ minh họa trong bài toán có thể được sử dụng để chứng minh các kết quả nào khác?  Hãy đưa ra một ví dụ.'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Ngoài các kết quả đã được chứng minh trong bài toán,  hình vẽ minh họa có thể được sử dụng để chứng minh các kết quả khác.  Ví dụ,  ta có thể chứng minh rằng tứ giác AMBN là tứ giác nội tiếp.  Để chứng minh điều này,  ta có thể sử dụng các góc nội tiếp và các góc ở tâm.  Cụ thể,  ta có:  góc AMB bằng 1/2 góc AOB (góc nội tiếp chắn cung AB).  Góc ANB bằng 1/2 góc AOB (góc ở tâm chắn cung AB).  Từ đó suy ra góc AMB bằng góc ANB,  hay tứ giác AMBN là tứ giác nội tiếp.'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbdt2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15a0c97049f4b5eb11256e3724b51ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images.zip:   0%|          | 0.00/1.16G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_processor.zip_and_upload_dir(\n",
    "  dir_path=f\"{Path.home()}/data/{DATA_NAME}/images\",\n",
    "  repo_id=f\"Vividbot/{DATA_NAME}\",\n",
    "  path_in_repo=\"images/images.zip\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f463f264184dd3a948579340de54f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "viet_openvivqa.jsonl:   0%|          | 0.00/12.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8ea5d52c7247d7b32bbd00fd3f13e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "viet_openvivqa.json:   0%|          | 0.00/14.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}.jsonl\",\n",
    "  repo_id=f\"Vividbot/{DATA_NAME}\",\n",
    "  path_in_repo=f\"{DATA_NAME_ALT}.jsonl\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True,\n",
    ")\n",
    "\n",
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}.json\",\n",
    "  repo_id=f\"Vividbot/{DATA_NAME}\",\n",
    "  path_in_repo=f\"{DATA_NAME_ALT}.json\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True,\n",
    ")\n",
    "\n",
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/{DATA_NAME}/conversation_{SAMPLE_COUNT}k.jsonl\",\n",
    "  repo_id=f\"Vividbot/{DATA_NAME}\",\n",
    "  path_in_repo=f\"conversation_{SAMPLE_COUNT}k.jsonl\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True,\n",
    ")\n",
    "\n",
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/{DATA_NAME}/detail_{SAMPLE_COUNT}k.jsonl\",\n",
    "  repo_id=f\"Vividbot/{DATA_NAME}\",\n",
    "  path_in_repo=f\"detail_{SAMPLE_COUNT}k.jsonl\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = json.loads(open(f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19188"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vividbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
