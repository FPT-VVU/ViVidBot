{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/bin/huggingface-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/huggingface_hub/commands/huggingface_cli.py\", line 52, in main\n",
      "    service.run()\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/huggingface_hub/commands/user.py\", line 98, in run\n",
      "    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 111, in login\n",
      "    _login(token, add_to_git_credential=add_to_git_credential, write_permission=write_permission)\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 307, in _login\n",
      "    raise ValueError(\"Invalid token passed!\")\n",
      "ValueError: Invalid token passed!\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from vividbot.data.processor.huggingface import HuggingFaceProcessor\n",
    "\n",
    "hf_processor = HuggingFaceProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = json.load(open(f\"{Path.home()}/data/openvivqa/vlsp2023_train_data.json\"))\n",
    "dev_data = json.load(open(f\"{Path.home()}/data/openvivqa/vlsp2023_dev_data.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_vivid_format(data, split=\"train\"):\n",
    "  images = data[\"images\"]\n",
    "  annotations = data[\"annotations\"]\n",
    "  new_data = []\n",
    "  for i, x in annotations.items():\n",
    "    image = images[str(x[\"image_id\"])]\n",
    "    new_data.append(\n",
    "      {\n",
    "        \"id\": i,\n",
    "        \"image\": f\"{split}-images/{image}\",\n",
    "        \"path\": \"Vividbot/openvivqa/images\",\n",
    "        \"conversations\": [\n",
    "          {\"from\": \"human\", \"value\": f\"<image>\\n{x['question']}\"},\n",
    "          {\"from\": \"gpt\", \"value\": x[\"answer\"]},\n",
    "        ],\n",
    "      }\n",
    "    )\n",
    "\n",
    "  return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data = convert_to_vivid_format(train_data, \"train\")\n",
    "new_dev_data = convert_to_vivid_format(dev_data, \"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30833, 3545)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_train_data), len(new_dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{Path.home()}/data/openvivqa/openvivqa_train.json\", \"w\") as f:\n",
    "  json.dump(new_train_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(f\"{Path.home()}/data/openvivqa/openvivqa_dev.json\", \"w\") as f:\n",
    "  json.dump(new_dev_data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1157be904a5a417096f7e54b98a5e2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-images.zip:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/openvivqa/train-images.zip\",\n",
    "  path_in_repo=\"images/train-images.zip\",\n",
    "  repo_id=\"Vividbot/openvivqa\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59fc0a55da24f2584e6bd0a399f8ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev-images.zip:   0%|          | 0.00/165M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/openvivqa/dev-images.zip\",\n",
    "  path_in_repo=\"images/dev-images.zip\",\n",
    "  repo_id=\"Vividbot/openvivqa\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vividbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
