{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab8ed7001974bb193db9631c400969b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"json\", data_files=\"openvivqa_submission.jsonl\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '940',\n",
       " 'image': 'dev-images/000000000000.jpg',\n",
       " 'question': '<image>\\nngười dân không được tụ tập quá bao nhiêu người ?',\n",
       " 'answer': '10 người',\n",
       " 'predicted': 'Người dân không được tụ tập quá 10 người.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_ids = set()\n",
    "for d in data:\n",
    "  if d[\"id\"] in duplicate_ids:\n",
    "    print(d[\"id\"])\n",
    "  duplicate_ids.add(d[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3545"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/langchain_core/utils/utils.py:225: UserWarning: WARNING! top_p is not default parameter.\n",
      "                top_p was transferred to model_kwargs.\n",
      "                Please confirm that top_p is what you intended.\n",
      "  warnings.warn(\n",
      "/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/langchain_core/utils/utils.py:225: UserWarning: WARNING! top_p is not default parameter.\n",
      "                top_p was transferred to model_kwargs.\n",
      "                Please confirm that top_p is what you intended.\n",
      "  warnings.warn(\n",
      "/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/langchain_groq/chat_models.py:355: UserWarning: WARNING! top_p is not default parameter.\n",
      "                    top_p was transferred to model_kwargs.\n",
      "                    Please confirm that top_p is what you intended.\n",
      "  warnings.warn(\n",
      "Parameter 'function'=<function process_batch at 0x777591d3dc60> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724567889.603103 1897806 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1724567889.630876 1897806 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1724567889.658086 1897806 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1724567889.686053 1897806 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "befda61d56d04f4bba362b0b4dac5648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3545 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1724567889.732662 1897806 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'image', 'question', 'answer', 'predicted'],\n",
       "    num_rows: 3545\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.cache import SQLiteCache\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from vividbot.data.task.vivid_instruct_65k.utils.llms import LLM\n",
    "\n",
    "os.makedirs(f\"{Path.home()}/.cache\", exist_ok=True)\n",
    "set_llm_cache(SQLiteCache(database_path=f\"{Path.home()}/.cache/.langchain.db\"))\n",
    "\n",
    "\n",
    "def get_generate_qa_pairs_chain():\n",
    "  return (\n",
    "    ChatPromptTemplate.from_messages(\n",
    "      [\n",
    "        (\n",
    "          \"system\",\n",
    "          \"Bạn là trợ lý đánh giá về độ chính xác của câu trả lời của một hệ thống AI.\"\n",
    "          \"Bạn được cung cấp một câu hỏi, một câu trả lời đúng và một câu trả lời dự đoán.\"\n",
    "          \"Nhiệm vụ của bạn là đánh giá xem câu trả lời dự đoán có đúng, gần đúng, hoặc tương tự hay không.\"\n",
    "          \"Câu trả lời đúng là câu trả lời mang thông tin đúng với trọng tâm của câu hỏi dù có thể mang nhiều thông tin khác.\"\n",
    "          \"Nếu câu trả lời dự đoán chứa thông tin đúng hoặc gần giống với ý chính của đáp án đúng và trọng tâm của câu hỏi hãy trả lời 1.\"\n",
    "          \"Các trường hợp có thể được coi là đúng bao gồm: câu trả lời chứa một phần thông tin chính xác, mô tả tương tự hoặc gần đúng với tình huống được mô tả trong đáp án đúng.\"\n",
    "          \"Nếu câu trả lời dự đoán hoàn toàn sai, không liên quan, hoặc mâu thuẫn với đáp án đúng, hãy trả lời 0.\"\n",
    "          \"Chỉ cần trả lời 0 hoặc 1 mà không cần giải thích.\"\n",
    "          \"Ví dụ: Câu hỏi: Ai là người đầu tiên đặt chân lên mặt trăng?\"\n",
    "          \"Đáp án đúng: Neil Armstrong\"\n",
    "          \"Câu trả lời: Neil Armstrong\"\n",
    "          \"Trả lời: 1\"\n",
    "          \"Ví dụ 2: Câu hỏi: Ai là người đầu tiên đặt chân lên mặt trăng?\"\n",
    "          \"Đáp án đúng: Neil Armstrong\"\n",
    "          \"Câu trả lời: Buzz Aldrin\"\n",
    "          \"Trả lời: 0\"\n",
    "          \"Ví dụ 3: Câu hỏi: Người đàn ông đang đeo gì sau lưng?\"\n",
    "          \"Đáp án đúng: một cái ba lô\"\n",
    "          \"Câu trả lời: Người đàn ông đang đeo một cái ba lô màu đen.\"\n",
    "          \"Trả lời: 1\"\n",
    "          \"Ví dụ 4: Câu hỏi: Người phụ nữ mặc áo đỏ đang làm gì?\"\n",
    "          \"Đáp án đúng: đang nói về khu bảo tàng mà các em học sinh đang tham quan\"\n",
    "          \"Câu trả lời: Người phụ nữ mặc áo đỏ đang đứng trước một nhóm học sinh.\"\n",
    "          \"Trả lời: 1\"\n",
    "          \"Ví dụ 5: Câu hỏi: Người đàn ông mặc áo đen đeo khẩu trang xanh da trời đang đẩy thứ gì?\"\n",
    "          \"Đáp án đúng: người đàn ông mặc áo đen đeo khẩu trang xanh da trời đang đẩy chiếc xe đẩy siêu thị màu đỏ\"\n",
    "          \"Câu trả lời: Người đàn ông đang đẩy một giỏ hàng.\"\n",
    "          \"Trả lời: 1\",\n",
    "        ),\n",
    "        (\n",
    "          \"human\",\n",
    "          \"Câu hỏi: {question}\\n\\nĐáp án đúng: {answer}\\n\\nCâu trả lời: {predicted}\\n\\nTrả lời:\",\n",
    "        ),\n",
    "      ]\n",
    "    )\n",
    "    | LLM\n",
    "    | StrOutputParser()\n",
    "  )\n",
    "\n",
    "\n",
    "def process_batch(batch):\n",
    "  batch_ids = batch[\"id\"]\n",
    "  batch_images = batch[\"image\"]\n",
    "  batch_questions = batch[\"question\"]\n",
    "  batch_answers = batch[\"answer\"]\n",
    "  batch_predicteds = batch[\"predicted\"]\n",
    "  processed_data = (\n",
    "    [json.loads(line) for line in open(\"openvivqa_scores.jsonl\")]\n",
    "    if os.path.exists(\"openvivqa_scores.jsonl\")\n",
    "    else []\n",
    "  )\n",
    "  processed_ids = [d[\"id\"] for d in processed_data]\n",
    "  for id, image, q, a, p in zip(\n",
    "    batch_ids, batch_images, batch_questions, batch_answers, batch_predicteds\n",
    "  ):\n",
    "    if id in processed_ids and id not in duplicate_ids:\n",
    "      continue\n",
    "    chain = get_generate_qa_pairs_chain()\n",
    "    score = float(\n",
    "      chain.invoke(\n",
    "        {\n",
    "          \"question\": q.replace(\"<image>\", \"\").strip(),\n",
    "          \"answer\": a,\n",
    "          \"predicted\": p,\n",
    "        }\n",
    "      )\n",
    "    )\n",
    "    d = {\n",
    "      \"id\": id,\n",
    "      \"image\": image,\n",
    "      \"question\": q,\n",
    "      \"answer\": a,\n",
    "      \"predicted\": p,\n",
    "      \"score\": score,\n",
    "    }\n",
    "    with open(\"openvivqa_scores.jsonl\", \"a\") as f:\n",
    "      f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "data.map(process_batch, batch_size=6, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [json.loads(line) for line in open(\"openvivqa_scores.jsonl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3377\n"
     ]
    }
   ],
   "source": [
    "correct = sum(s[\"score\"] for s in scores)\n",
    "total = len(scores)\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrects = [s for s in scores if s[\"score\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1256"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corrects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '28234',\n",
       " 'question': '<image>\\nngười phụ nữ mặc áo màu vàng mang dù màu gì ?',\n",
       " 'answer': 'dù màu xanh dương',\n",
       " 'predicted': 'Người phụ nữ mặc áo màu vàng mang dù màu xanh dương.',\n",
       " 'score': 1.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "d = [json.loads(line) for line in open(\"83k_openvivqa_scores.jsonl\").readlines()]\n",
    "d = sorted(d, key=lambda x: int(x[\"id\"]))\n",
    "with open(\"83k_openvivqa_scores_sorted.jsonl\", \"w\") as f:\n",
    "  for x in d:\n",
    "    f.write(json.dumps(x, ensure_ascii=False) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vividbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
