{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/bin/huggingface-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/huggingface_hub/commands/huggingface_cli.py\", line 52, in main\n",
      "    service.run()\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/huggingface_hub/commands/user.py\", line 98, in run\n",
      "    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 111, in login\n",
      "    _login(token, add_to_git_credential=add_to_git_credential, write_permission=write_permission)\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 305, in _login\n",
      "    permission = get_token_permission(token)\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/huggingface_hub/hf_api.py\", line 1538, in get_token_permission\n",
      "    return self.whoami(token=token)[\"auth\"][\"accessToken\"][\"role\"]\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/huggingface_hub/hf_api.py\", line 1500, in whoami\n",
      "    r = get_session().get(\n",
      "  File \"/home/dminhvu/.local/lib/python3.10/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "  File \"/home/dminhvu/.local/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/dminhvu/.local/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/site-packages/huggingface_hub/utils/_http.py\", line 66, in send\n",
      "    return super().send(request, *args, **kwargs)\n",
      "  File \"/home/dminhvu/.local/lib/python3.10/site-packages/requests/adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/dminhvu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 793, in urlopen\n",
      "    response = self._make_request(\n",
      "  File \"/home/dminhvu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 537, in _make_request\n",
      "    response = conn.getresponse()\n",
      "  File \"/home/dminhvu/.local/lib/python3.10/site-packages/urllib3/connection.py\", line 466, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/http/client.py\", line 1368, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/http/client.py\", line 317, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/http/client.py\", line 278, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/ssl.py\", line 1273, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/dminhvu/miniconda3/envs/vividbot/lib/python3.10/ssl.py\", line 1129, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from vividbot.data.processor.huggingface import HuggingFaceProcessor\n",
    "\n",
    "hf_processor = HuggingFaceProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(\n",
    "  open(f\"{Path.home()}/data/vivid-ielts-writing/vivid_ielts_writing.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "  if len(d[\"conversations\"]) == 0:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "  conv = d[\"conversations\"]\n",
    "  for c in conv:\n",
    "    if c[\"from\"] not in [\"system\", \"human\", \"gpt\"]:\n",
    "      print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "longs = []\n",
    "\n",
    "for d in data:\n",
    "  total_word_count = 0\n",
    "  conv = d[\"conversations\"]\n",
    "  for c in conv:\n",
    "    total_word_count += len(c[\"value\"].split())\n",
    "    if total_word_count > 1000:\n",
    "      longs.append(d)\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'cambridge_12_test_7_task_1',\n",
       " 'image': 'images/cambridge_12_test_7_task_1.png',\n",
       " 'conversations': [{'from': 'system',\n",
       "   'value': 'Bạn là một chuyên gia về tiếng Anh học thuật, đặc biệt là IELTS Writing. Hãy hỗ trợ người dùng với bài viết sau.'},\n",
       "  {'from': 'human',\n",
       "   'value': '<image>\\nĐề bài: The chart below shows how frequently people in the USA ate in fast food restaurants between 2003 and 2013.\\n\\nSummarise the information by selecting and reporting the main features, and make comparisons where relevant.\\n\\nHãy đưa ra dàn ý chi tiết cho đề bài trên.'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Introduction: Paraphrase lại đề bài\\n- Biểu đồ so sánh tần suất người dân ở Mỹ ăn tại các cửa hàng thức ăn nhanh từ năm 2003 đến 2013.\\n\\nOverview: Nêu hai đặc điểm chính của biểu đồ\\n- 2003 và 2006: Hầu hết mọi người ăn 1 lần mỗi tuần\\n- 2013: Hầu hết mọi người chỉ ăn 1-2 lần mỗi tháng\\n\\nBody paragraph 1: Mô tả hai số liệu cao nhất (once a week và once or twice a month)\\n- Năm 2003: Khoảng một phần ba người Mỹ ăn hàng tuần, cao hơn một chút so với những người ăn 1-2 lần mỗi tháng.\\n- Năm 2013: Tỉ lệ người ăn 1-2 lần mỗi tháng cao hơn, trong khi tỉ lệ ăn hàng tuần giảm.\\n\\nBody paragraph 2: Mô tả các số liệu còn lại và sự thay đổi của chúng sau 10 năm\\n- Khoảng 17% ăn vài lần mỗi tuần, 13% ăn một vài lần trong năm; hai nhóm này không thay đổi nhiều.\\n- Chỉ khoảng 5% không ăn tại các cửa hàng thức ăn nhanh, con số này cũng không thay đổi nhiều.'},\n",
       "  {'from': 'human', 'value': 'Hãy viết bài mẫu cho tôi.'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Tôi rất sẵn lòng. Sau đây là bài viết mẫu cho đề bài trên:\\n\\nThe bar chart illustrates the frequency of visits by Americans to fast food establishments between 2003 and 2013.\\n\\nIn general, the data reveals a shift in eating habits over the decade, with a decline in the frequency of visits to fast food outlets. Initially, in 2003 and 2006, the majority of Americans dined at fast food restaurants once a week. However, by 2013, the highest proportion of individuals visited these establishments only once or twice a month.\\n\\nIn 2003, approximately one-third of Americans patronized fast food restaurants on a weekly basis, slightly surpassing the percentage of those who visited once or twice per month. Over the following decade, the frequency of weekly visits experienced a modest increase of around 2% in 2006, followed by a decline of approximately 5% by 2013. Conversely, the proportion of individuals visiting once or twice per month saw an upward trend, rising from 25% in 2003 to approximately 33% by 2013.\\n\\nInitially, around 17% of Americans frequented fast food establishments several times each week, while approximately 13% visited only a few times a year. These percentages remained relatively stable over the decade, hovering around 15% for both categories by 2013. Notably, the data also indicates that only about 5% of Americans refrained from dining at fast food restaurants, a figure slightly higher than the percentage of daily visitors. However, these percentages exhibited minimal variation over the ten-year period.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'Những từ vựng nào giúp tôi tăng điểm trong đề bài này?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Để tăng điểm trong đề bài này, bạn nên sử dụng các từ ngữ liên quan đến tần suất và sự thay đổi. Dưới đây là các từ vựng được sử dụng trong bài viết mẫu:\\n- dine: ăn tối hoặc dùng bữa ăn chính trong một môi trường thoải mái và dễ chịu, thường là ở nhà hàng hoặc nhà ăn.\\n- patronize: ủng hộ, sử dụng dịch vụ hoặc mua hàng từ một cửa hàng, doanh nghiệp hoặc tổ chức nhất định.\\n- surpass: vượt qua, vượt lên trên ai hoặc cái gì đó về chất lượng hoặc hiệu suất.\\n- modest: khiêm tốn, không tự kiêu, không quá nổi bật hoặc quá phô trương.\\n- conversely: ngược lại, dùng để chỉ sự phản đối hoặc sự tương phản giữa hai ý hay hai tình huống.\\n- frequent: thường xuyên đến một nơi, tham gia vào một hoạt động, hoặc sử dụng một dịch vụ một cách đều đặn.\\n- hover: bay nhẹ nhàng trong không khí, đặc biệt là ở một vị trí cố định gần một nơi nào đó.\\n- refrain from: kiềm chế hoặc ngừng làm một điều gì đó, đặc biệt là điều gì đó mà bạn muốn làm nhưng biết rằng nó không phù hợp hoặc không tốt.\\n- minimal: tối thiểu, rất nhỏ hoặc ít nhất cần thiết.'},\n",
       "  {'from': 'human', 'value': 'Hãy dịch bài viết mẫu trên sang tiếng Việt.'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Biểu đồ bảng so sánh tần suất người dân ở Mỹ ăn tại các cửa hàng thức ăn nhanh từ năm 2003 đến 2013.\\n\\nNhìn chung, dữ liệu cho thấy sự thay đổi trong thói quen ăn uống trong suốt thập kỷ, với sự giảm sút về tần suất đến các cửa hàng thức ăn nhanh. Ban đầu, vào năm 2003 và 2006, phần lớn người Mỹ ăn tại các cửa hàng thức ăn nhanh một lần mỗi tuần. Tuy nhiên, đến năm 2013, tỷ lệ cao nhất của những người đến đây chỉ là một hoặc hai lần mỗi tháng.\\n\\nVào năm 2003, khoảng một phần ba người Mỹ thường xuyên ăn tại các cửa hàng thức ăn nhanh hàng tuần, cao hơn một chút so với những người ăn một hoặc hai lần mỗi tháng. Trong thập kỷ tiếp theo, tần suất đến hàng tuần đã tăng nhẹ khoảng 2% vào năm 2006, sau đó giảm khoảng 5% vào năm 2013. Ngược lại, tỷ lệ người đến một hoặc hai lần mỗi tháng đã tăng lên, từ 25% vào năm 2003 lên khoảng 33% vào năm 2013.\\n\\nBan đầu, khoảng 17% người Mỹ thường xuyên đến các cửa hàng thức ăn nhanh vài lần mỗi tuần, trong khi khoảng 13% chỉ đến vài lần trong năm. Những tỷ lệ này vẫn ổn định trong suốt thập kỷ, duy trì quanh mức 15% cho cả hai nhóm vào năm 2013. Đặc biệt, dữ liệu cũng cho thấy chỉ có khoảng 5% người Mỹ không ăn tại các cửa hàng thức ăn nhanh, con số này cao hơn một chút so với tỷ lệ người ăn hàng ngày. Tuy nhiên, những tỷ lệ này chỉ có sự thay đổi tối thiểu trong suốt mười năm.'}]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SYSTEM_MESSAGE = [\n",
    "  \"Bạn là chuyên gia tiếng Anh học thuật và IELTS Writing. Hãy hỗ trợ người dùng với câu hỏi của họ.\",\n",
    "  \"Hãy đóng vai một học giả tiếng Anh và hỗ trợ người dùng với câu hỏi của họ.\",\n",
    "  \"Nhiệm vụ của bạn là trở thành một chuyên gia về IELTS và giải đáp thắc mắc của người dùng.\",\n",
    "  \"Bạn được cung cấp một hình ảnh và một đề bài IELTS Writing Task 1. Hãy hỗ trợ người dùng nếu họ cần.\",\n",
    "]\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "  d[\"conversations\"][0][\"value\"] = _SYSTEM_MESSAGE[i % len(_SYSTEM_MESSAGE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sorted(data, key=lambda x: x[\"id\"])\n",
    "data = [{**d, \"path\": \"Vividbot/vivid-ielts-writing/images\"} for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{Path.home()}/data/vivid-ielts-writing/vivid_ielts_writing.json\", \"w\") as f:\n",
    "  json.dump(data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 342.16it/s]\n",
      "200it [00:00, 330.46it/s]\n",
      "200it [00:00, 311.90it/s]\n",
      "200it [00:00, 337.02it/s]\n",
      "200it [00:00, 359.35it/s]\n",
      "200it [00:00, 354.22it/s]\n",
      "200it [00:00, 319.99it/s]\n",
      "200it [00:00, 272.15it/s]\n",
      "200it [00:00, 287.77it/s]\n",
      "200it [00:00, 362.98it/s]\n",
      "200it [00:00, 386.30it/s]\n",
      "200it [00:00, 306.34it/s]\n",
      "200it [00:00, 248.49it/s]\n",
      "200it [00:00, 292.91it/s]\n",
      "200it [00:00, 263.86it/s]\n",
      "200it [00:00, 317.97it/s]\n",
      "200it [00:00, 357.54it/s]\n",
      "200it [00:00, 298.94it/s]\n",
      "200it [00:00, 392.11it/s]\n",
      "200it [00:00, 288.75it/s]\n",
      "200it [00:00, 299.06it/s]\n",
      "200it [00:00, 350.76it/s]\n",
      "200it [00:00, 377.19it/s]\n",
      "200it [00:00, 366.10it/s]\n",
      "200it [00:00, 353.17it/s]\n",
      "200it [00:00, 347.88it/s]\n",
      "200it [00:00, 329.89it/s]\n",
      "200it [00:00, 359.12it/s]\n",
      "200it [00:00, 325.59it/s]\n",
      "200it [00:00, 359.14it/s]\n",
      "200it [00:00, 403.81it/s]\n",
      "200it [00:00, 402.10it/s]\n",
      "200it [00:00, 378.94it/s]\n",
      "200it [00:00, 367.95it/s]\n",
      "200it [00:00, 332.61it/s]\n",
      "200it [00:00, 310.59it/s]\n",
      "200it [00:00, 345.67it/s]\n",
      "200it [00:00, 411.50it/s]\n",
      "75it [00:00, 471.01it/s]\n",
      "74it [00:00, 375.77it/s]\n",
      "200it [00:00, 337.93it/s]\n",
      "75it [00:00, 422.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'image', 'description', 'conversations'],\n",
       "    num_rows: 8024\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_DESCRIPTION_QUESTIONS = [\n",
    "  \"Nội dung của hình ảnh là gì?\",\n",
    "  \"Hãy mô tả hình ảnh này.\",\n",
    "  \"Hãy cho biết nội dung của hình ảnh?\",\n",
    "  \"Trong hình ảnh này có gì?\",\n",
    "  \"Viết một đoạn mô tả về hình ảnh này.\",\n",
    "  \"Bức ảnh này chụp về chủ đề gì?\",\n",
    "  \"Đây là hình ảnh về gì?\",\n",
    "  \"Đây là gì?\",\n",
    "  \"Hình ảnh này là gì?\",\n",
    "  \"Mô tả bức ảnh này.\",\n",
    "]\n",
    "\n",
    "\n",
    "hf_processor = HuggingFaceProcessor()\n",
    "\n",
    "\n",
    "def get_random_description_question(id: Optional[int]) -> str:\n",
    "  if id:\n",
    "    return _DESCRIPTION_QUESTIONS[id % len(_DESCRIPTION_QUESTIONS)]\n",
    "  else:\n",
    "    return np.random.choice(_DESCRIPTION_QUESTIONS)\n",
    "\n",
    "\n",
    "DATA_NAME = \"viet-openvivqa\"\n",
    "DATA_NAME_ALT = DATA_NAME.replace(\"-\", \"_\")\n",
    "SAMPLE_COUNT = round(len(ds) / 1000)\n",
    "\n",
    "os.makedirs(f\"{Path.home()}/data/{DATA_NAME}\", exist_ok=True)\n",
    "os.makedirs(f\"{Path.home()}/data/{DATA_NAME}/images\", exist_ok=True)\n",
    "\n",
    "\n",
    "def convert_message(message: dict):\n",
    "  role = message[\"role\"]\n",
    "  content = message[\"content\"]\n",
    "\n",
    "  return {\"from\": \"human\" if role == \"user\" else \"gpt\", \"value\": content}\n",
    "\n",
    "\n",
    "fails = []\n",
    "\n",
    "\n",
    "def process(batch: dict):\n",
    "  batch_ids = batch[\"id\"]\n",
    "  batch_images = batch[\"image\"]\n",
    "  batch_descriptions = batch[\"description\"]\n",
    "  batch_conversations = batch[\"conversations\"]\n",
    "\n",
    "  conversation_data = []\n",
    "  detail_data = []\n",
    "\n",
    "  for i, (id, image, description, conversations) in tqdm(\n",
    "    enumerate(zip(batch_ids, batch_images, batch_descriptions, batch_conversations))\n",
    "  ):\n",
    "    saved = False\n",
    "    img_exts = [image.format.lower()] if image.format else [\"jpg\", \"png\"]\n",
    "    for img_ext in img_exts:\n",
    "      try:\n",
    "        # save image\n",
    "        if not os.path.exists(f\"{Path.home()}/data/{DATA_NAME}/images/{id}.{img_ext}\"):\n",
    "          image.save(f\"{Path.home()}/data/{DATA_NAME}/images/{id}.{img_ext}\")\n",
    "\n",
    "        conversations = [convert_message(message) for message in conversations][:6]\n",
    "        if len(conversations) == 0:\n",
    "          continue\n",
    "\n",
    "        if np.random.rand() < 0.5:\n",
    "          conversations[0][\"value\"] = f\"{conversations[0]['value']}\\n<image>\"\n",
    "        else:\n",
    "          conversations[0][\"value\"] = f\"<image>\\n{conversations[0]['value']}\"\n",
    "\n",
    "        conversation_data.append(\n",
    "          {\n",
    "            \"id\": id,\n",
    "            \"image\": f\"images/{id}.{img_ext}\",\n",
    "            \"conversations\": conversations,\n",
    "          }\n",
    "        )\n",
    "\n",
    "        detail_data.append(\n",
    "          {\n",
    "            \"id\": id,\n",
    "            \"image\": f\"images/{id}.{img_ext}\",\n",
    "            \"conversations\": [\n",
    "              {\n",
    "                \"from\": \"human\",\n",
    "                \"value\": f\"<image>\\n{get_random_description_question(id=i)}\"\n",
    "                if i % 2 == 0\n",
    "                else f\"{get_random_description_question(id=i)}\\n<image>\",\n",
    "              },\n",
    "              {\"from\": \"gpt\", \"value\": description},\n",
    "            ],\n",
    "          }\n",
    "        )\n",
    "\n",
    "        saved = True\n",
    "        break\n",
    "      except Exception:\n",
    "        continue\n",
    "\n",
    "    if not saved:\n",
    "      print(f\"Failed to save image {id}\")\n",
    "      fails.append(\n",
    "        {\n",
    "          \"id\": id,\n",
    "          \"image\": image,\n",
    "          \"description\": description,\n",
    "          \"conversations\": conversations,\n",
    "        }\n",
    "      )\n",
    "\n",
    "  with open(\n",
    "    f\"{Path.home()}/data/{DATA_NAME}/conversation_{SAMPLE_COUNT}k.jsonl\", \"a\"\n",
    "  ) as f:\n",
    "    for d in conversation_data:\n",
    "      f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "  with open(f\"{Path.home()}/data/{DATA_NAME}/detail_{SAMPLE_COUNT}k.jsonl\", \"a\") as f:\n",
    "    for d in detail_data:\n",
    "      f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "\n",
    "disable_progress_bar()\n",
    "\n",
    "ds.map(process, batched=True, batch_size=200, num_proc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8024\n",
      "8024\n"
     ]
    }
   ],
   "source": [
    "processed_conversation_data = open(\n",
    "  f\"{Path.home()}/data/{DATA_NAME}/conversation_{SAMPLE_COUNT}k.jsonl\"\n",
    ").readlines()\n",
    "processed_detail_data = open(\n",
    "  f\"{Path.home()}/data/{DATA_NAME}/detail_{SAMPLE_COUNT}k.jsonl\"\n",
    ").readlines()\n",
    "\n",
    "processed_conversation_data = [json.loads(d) for d in processed_conversation_data]\n",
    "processed_detail_data = [json.loads(d) for d in processed_detail_data]\n",
    "\n",
    "print(len(processed_conversation_data))\n",
    "print(len(processed_detail_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = processed_detail_data + processed_conversation_data\n",
    "\n",
    "combined_data = sorted(combined_data, key=lambda x: x[\"id\"])\n",
    "combined_data = [{**d, \"path\": f\"Vividbot/{DATA_NAME}/images\"} for d in combined_data]\n",
    "\n",
    "with open(f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}.jsonl\", \"w\") as f:\n",
    "  for d in combined_data:\n",
    "    f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "with open(f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}.json\", \"w\") as f:\n",
    "  f.write(json.dumps(combined_data, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "t = \"KEN COFFEE\\n03 Chế Lan Viên, Quy Nhơn\\n\\nCAFE\\nCafe đen/ cafe đá\\nEspresso/ espresso đá\\nCafe sữa/ cafe sữa đá\\nBạc sỉu đá/ espresso sữa đá\\nTrà gừng nóng\\nTrà lipton đá/ nóng\\nCa cao sữa đá/ nóng\\nSoda chanh\\n\\nNƯỚC ÉP TRÁI CÂY\\nChanh tươi\\nCam vắt\\nỔi ép\\nCa Chua ép\\nCa Đá Lạt\\nNước dừa tươi\\n\\nSỮA - SỮA CHUA\\nSữa chua\\nSữa chua đá\\nSữa chua cafe\\nSữa vinamilk hộp\\nSữa đậu xanh\\n\\nNƯỚC NGỌT\\nSting, Pepsi, Rivive\\n7up, Number one\\nNuti\\nBò Húc\\nKingdang Lavie\\n\\nBÁNH VÀ ĐỒ ĂN VẶT\\nHạt hướng dương\\nHạt dưa\\nMực bento\\nKhoai ga\\n\\n\\n\\nKEN COFFEE\\n03 Chế Lan Viên, Quy Nhơn\\n\\nCAFE\\nCafe đen/ cafe đá\\nEspresso/ espresso đá\\nCafe sữa/ cafe sữa đá\\nBạc sỉu đá/ espresso sữa đá\\nTrà gừng nóng\\nTrà lipton đá/ nóng\\nCa cao sữa đá/ nóng\\nSoda chanh\\n\\nNƯỚC ÉP TRÁI CÂY\\nChanh tươi\\nCam vắt\\nỔi ép\\nCa Chua ép\\nCa Đá Lạt\\nNước dừa tươi\\n\\nSỮA - SỮA CHUA\\nSữa chua\\nSữa chua đá\\nSữa chua cafe\\nSữa vinamilk hộp\\nSữa đậu xanh\\n\\nNƯỚC NGỌT\\nSting, Pepsi, Rivive\\n7up, Number one\\nNuti\\nBò Húc\\nKingdang Lavie\\n\\nBÁNH VÀ ĐỒ ĂN VẶT\\nHạt hướng dương\\nHạt dưa\\nMực bento\\nKhoai ga\\n\"\n",
    "print(len(re.split(r\"[\\n ]+\", t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbdt2 = json.loads(\n",
    "  open(\n",
    "    f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}_{SAMPLE_COUNT*2}k_all.json\"\n",
    "  ).read()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'image': 'images/0.jpeg',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nBài toán yêu cầu chứng minh điều gì ở phần a)?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Phần a) của bài toán yêu cầu chứng minh rằng OPQ là tam giác cân. Lời giải cho phần này dựa vào việc chứng minh tứ giác MBQO là tứ giác nội tiếp, từ đó suy ra hai góc MQQ và MBO bằng nhau (cùng chắn cung MO). Tiếp theo, tương tự với tứ giác MPCO,  ta cũng có hai góc MPO và MCO bằng nhau.  Từ đó suy ra góc MPO bằng góc MQO,  hay tam giác OPQ cân tại O.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'Phần b) của bài toán giải quyết vấn đề gì?  Nêu rõ các bước chứng minh.'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Phần b) của bài toán yêu cầu chứng minh rằng CR bằng HM.  Để chứng minh điều này,  bài toán sử dụng các tam giác đồng dạng.  Cụ thể,  ta có tam giác APR đồng dạng với tam giác ACOH.  Từ đó suy ra tỉ lệ:  PC/RC = CO/OH.  Tiếp theo,  ta có tam giác AMOH đồng dạng với tam giác APOC,  từ đó suy ra tỉ lệ:  MH/HO = PC/OC.  Kết hợp hai tỉ lệ trên,  ta suy ra CR bằng MH.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'Phần c) của bài toán muốn chứng minh điều gì?  Cách giải quyết như thế nào?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Phần c) của bài toán yêu cầu chứng minh rằng tứ giác ACDK là tứ giác nội tiếp.  Để chứng minh điều này,  bài toán sử dụng các tam giác đồng dạng.  Cụ thể,  ta có tam giác AHB đồng dạng với tam giác ACO,  từ đó suy ra tỉ lệ:  AB/BH = AO/CO.  Tiếp theo,  ta có tam giác ABK đồng dạng với tam giác AOD,  từ đó suy ra tỉ lệ:  AB/BK = AO/OD.  Kết hợp hai tỉ lệ trên,  ta suy ra góc AKB bằng góc ADO.  Từ đó,  ta kết luận rằng tứ giác ACDK là tứ giác nội tiếp.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'Phần d) của bài toán giải quyết vấn đề gì?  Nêu rõ các bước chứng minh.'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Phần d) của bài toán yêu cầu chứng minh rằng ABEC là hình thoi.  Để chứng minh điều này,  bài toán sử dụng tính chất của điểm đối xứng.  Cụ thể,  do K là điểm đối xứng với H qua B,  nên KB bằng KH.  Tiếp theo,  do tứ giác ACDK là tứ giác nội tiếp,  nên góc KAB bằng góc KEB.  Kết hợp hai điều trên,  ta suy ra ABEC là hình thoi.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'Hình vẽ minh họa trong bài toán có thể được sử dụng để chứng minh các kết quả nào khác?  Hãy đưa ra một ví dụ.'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Ngoài các kết quả đã được chứng minh trong bài toán,  hình vẽ minh họa có thể được sử dụng để chứng minh các kết quả khác.  Ví dụ,  ta có thể chứng minh rằng tứ giác AMBN là tứ giác nội tiếp.  Để chứng minh điều này,  ta có thể sử dụng các góc nội tiếp và các góc ở tâm.  Cụ thể,  ta có:  góc AMB bằng 1/2 góc AOB (góc nội tiếp chắn cung AB).  Góc ANB bằng 1/2 góc AOB (góc ở tâm chắn cung AB).  Từ đó suy ra góc AMB bằng góc ANB,  hay tứ giác AMBN là tứ giác nội tiếp.'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbdt2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194756bae05540e591e32375832ae9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images.zip:   0%|          | 0.00/11.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_processor.zip_and_upload_dir(\n",
    "  dir_path=f\"{Path.home()}/data/vivid-ielts-writing/images\",\n",
    "  repo_id=\"Vividbot/vivid-ielts-writing\",\n",
    "  path_in_repo=\"images/images.zip\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/vivid-ielts-writing/vivid_ielts_writing.json\",\n",
    "  repo_id=\"Vividbot/vivid-ielts-writing\",\n",
    "  path_in_repo=\"vivid_ielts_writing.json\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f463f264184dd3a948579340de54f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "viet_openvivqa.jsonl:   0%|          | 0.00/12.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8ea5d52c7247d7b32bbd00fd3f13e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "viet_openvivqa.json:   0%|          | 0.00/14.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}.jsonl\",\n",
    "  repo_id=f\"Vividbot/{DATA_NAME}\",\n",
    "  path_in_repo=f\"{DATA_NAME_ALT}.jsonl\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True,\n",
    ")\n",
    "\n",
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}.json\",\n",
    "  repo_id=f\"Vividbot/{DATA_NAME}\",\n",
    "  path_in_repo=f\"{DATA_NAME_ALT}.json\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True,\n",
    ")\n",
    "\n",
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/{DATA_NAME}/conversation_{SAMPLE_COUNT}k.jsonl\",\n",
    "  repo_id=f\"Vividbot/{DATA_NAME}\",\n",
    "  path_in_repo=f\"conversation_{SAMPLE_COUNT}k.jsonl\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True,\n",
    ")\n",
    "\n",
    "hf_processor.upload_file(\n",
    "  file_path=f\"{Path.home()}/data/{DATA_NAME}/detail_{SAMPLE_COUNT}k.jsonl\",\n",
    "  repo_id=f\"Vividbot/{DATA_NAME}\",\n",
    "  path_in_repo=f\"detail_{SAMPLE_COUNT}k.jsonl\",\n",
    "  repo_type=\"dataset\",\n",
    "  overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = json.loads(open(f\"{Path.home()}/data/{DATA_NAME}/{DATA_NAME_ALT}.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19188"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vividbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
