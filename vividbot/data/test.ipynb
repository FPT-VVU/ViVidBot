{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count (x):\n",
    "    return len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clip_id': 'G1DRYgjsZTw.63', 'clip_span': ['00:10:42.190', '00:10:48.640'], 'url': 'https://www.youtube.com/watch?v=G1DRYgjsZTw', 'vision_cap': ['a man is using a spoon to scoop something out of a pan that is sitting on top of a pan.', 'a chef pours ingredients on a tray and then adds some green food.', 'a person is using a green bottle on something and is stirring it.', 'an individual pours a sauce in his hand onto some type of food', 'a person is pouring food into a tray of pans and then mixing it'], 'audio_cap': ['someone talking about something.', 'someone is speaking.', 'a man is telling something.', 'someone is speaking.', 'a man is speaking.'], 'subtitle': 'How much it helps you from technology to show them the cell phone on the map and nobody will look for you to make a deal. Nobody is going to want to steal you.', 'vast_cap': 'A man is using a spoon to scoop something out of a pan while speaking about how technology helps to show the location on a map and avoid being stolen.'}\n",
      "{'clip_id': 'QvztEHMXbr0.20', 'clip_span': ['00:03:57.380', '00:04:04.310'], 'url': 'https://www.youtube.com/watch?v=QvztEHMXbr0', 'vision_cap': ['a man sitting in front of a desk is talking about music, then begins to talk.', 'a man sits in a room with a recording equipment and explains how to use it.', 'a man sits at a desk and talks into the camera.', 'this is an interview where the person in the studio is talking about the sound', 'a man in a recording studio talks about his recording techniques.'], 'audio_cap': ['someone is speaking.', 'a man is speaking.', 'a man is talking about something.', 'a man is speaking.', 'man is speaking.'], 'subtitle': 'Are you gonna make a ton? Probably not but thats, not the point here.', 'vast_cap': \"A man sitting in front of a desk is talking about music, then begins to talk, probably not but that's not the point here.\"}\n",
      "{'clip_id': 'u54htn7zPJY.2', 'clip_span': ['00:00:15.700', '00:00:26.769'], 'url': 'https://www.youtube.com/watch?v=u54htn7zPJY', 'vision_cap': ['man demonstrating a cellphone features while describing the features.', \"a person is holding a cell phone that they're going to talk on it.\", 'a male person is showing the screen of a cell phone and then is demonstrating it as he shows it off', 'a man describes and demonstrates a cellphone and the screen.', 'a person holds their cell phone, and uses it to show their screen.'], 'audio_cap': ['a sound is being recorded.', 'a person is telling their story.', 'someone is saying \" the end of a song.', 'a sound was made by a friend.', 'a sound is being recorded.'], 'subtitle': 'It is available with the 45 per month plan, which includes unlimited voice, messaging and data, which is pretty good.', 'vast_cap': 'A male person is demonstrating the features of a cell phone with a 45 per month plan that includes unlimited voice, messaging, and data.'}\n",
      "{'clip_id': '8ibTgaRWAAo.32', 'clip_span': ['00:04:30.479', '00:04:37.120'], 'url': 'https://www.youtube.com/watch?v=8ibTgaRWAAo', 'vision_cap': ['a man is playing a first person shooter game', 'a person is playing a game', 'a person is playing a video game', 'a video game is being played', 'a video game is played'], 'audio_cap': ['a gun was shot with a double - shot shot.', 'someone is shooting at a target, making a bang.', 'someone is playing a shooting game and explaining their shooting.', 'gun sound for a shooter.', 'someone is playing video games with a teammates.'], 'subtitle': 'As long as I did, I really dont. Oh, I got a shotgun.', 'vast_cap': 'A person is playing a video game while shooting at a target, making a bang, and expressing surprise.'}\n",
      "{'clip_id': '1omxuo26Pmk.65', 'clip_span': ['00:11:02.880', '00:11:09.760'], 'url': 'https://www.youtube.com/watch?v=1omxuo26Pmk', 'vision_cap': ['a young girl is talking to a camera and then winks at the camera', 'a woman is sitting down in a room making faces to the camera.', 'a woman is singing and laughing about something. she is laughing in front of her.', 'a young woman is talking about a song that is playing in the background.', 'a woman is sitting in front of a mirror with a man talking in front of her'], 'audio_cap': ['a young woman is speaking.', 'someone is asking a message.', 'someone is asking a message.', 'a young woman is speaking.', 'someone says \" it\\'s my business. \".'], 'subtitle': 'Thank you so much for watching this video. I hope you have the best day and the best week, and I wish you all the best its, not a video.', 'vast_cap': 'A young woman is thanking the viewer for watching the video and wishes them a good day, week, and life.'}\n",
      "{'clip_id': 'dGKjwnqs3AA.0', 'clip_span': ['00:00:00.030', '00:00:11.010'], 'url': 'https://www.youtube.com/watch?v=dGKjwnqs3AA', 'vision_cap': ['the person is holding a cell phone', 'the man is holding a cellphone', 'a man is speaking over a phone', 'a person is holding a cell phone in his hand and turning it', 'a person is holding an unplugging cell phone'], 'audio_cap': ['a voice is speaking a message in a specific language.', 'an electronic device is being played.', 'someone is speaking a message on a cell phone.', 'someone is speaking a message on a cell phone.', 'people are speaking.'], 'subtitle': 'Hey guys youre watching phone rhiness in that video review of the tmobile mytouch 3G slide, which is available right now through tmobile for the price of one 7999 on contract.', 'vast_cap': 'A man is speaking over a phone and an electronic device is being played, and he is reviewing the T-Mobile MyTouch 3G Slide, which is available for $799.'}\n",
      "{'clip_id': 'HTiBbayu1tg.25', 'clip_span': ['00:02:49.240', '00:02:55.600'], 'url': 'https://www.youtube.com/watch?v=HTiBbayu1tg', 'vision_cap': ['a man driving in a car and he has a glass screen on his face.', 'a car driving down a highway is shown from the front seat.', 'a man is driving a car in an electronic glasses.', 'the person is using a screen with a circle on it to see how far it was going.', 'a car is driving down the highway with an orange screen on its side'], 'audio_cap': ['someone is talking in a sports car.', 'a car is driving in a narrow traffic jam.', 'someone is talking in a sports car.', 'cars are driving in reverse.', 'car engine starting.'], 'subtitle': 'Hey! (Car brakes screeching) Did you see that? Dorsa: Good job though. Maddie: That guy almost killed us.', 'vast_cap': 'A man is driving a car in an electronic glasses, someone is talking in a sports car, and someone praised the driver for avoiding an accident.'}\n",
      "{'clip_id': 'ymqsI0rN8YU.30', 'clip_span': ['00:05:12.260', '00:05:24.880'], 'url': 'https://www.youtube.com/watch?v=ymqsI0rN8YU', 'vision_cap': ['a man talks about a mobile phone and a phone.', 'a person that is talking in front of a desk.', 'a man wearing a dark red coat stands in an office..', 'a man talking about an electronic phone and how it looks.', 'a man in red suit and black jacket is talking about a mobile phone.'], 'audio_cap': ['someone is speaking.', 'a man is speaking.', 'a man is speaking in a broadcast.', 'a man is speaking.', 'a man is speaking.'], 'subtitle': 'Also knows a my phone here. Lol was killed for indian compa value, namely, and 10 women been disabled for nest on visas had gone into that.', 'vast_cap': 'A man wearing a dark red coat stands in an office and speaks, mentioning that he also knows a phone and that 10 women have been disabled for nest visas.'}\n",
      "{'clip_id': '2Raa9z_sfoc.12', 'clip_span': ['00:02:12.040', '00:02:20.220'], 'url': 'https://www.youtube.com/watch?v=2Raa9z_sfoc', 'vision_cap': ['someone is showing how to use his game system', 'a person is playing a video game on a tablet.', 'a screen with a map and hands is being displayed, then the screen is shown where an map is.', 'a person is explaining how to use the game in a video game', 'an individual uses a game of war on a tablet to control a video game.'], 'audio_cap': ['someone is announcing a news break.', 'someone is announcing that a news report is heard.', 'someone is speaking.', 'someone is announcing a news break.', 'someone is speaking.'], 'subtitle': 'But for that I have all subscribe to our channel youtube. Follow the news on glaficom and with you there was a glass all thanks to everyone.', 'vast_cap': 'But for that, I have all the news subscribed to our channel on YouTube, and thanks to everyone, there was a glass all thanks to Glaficom.'}\n",
      "{'clip_id': 'WrT6tQzmSTE.7', 'clip_span': ['00:00:54.899', '00:01:06.299'], 'url': 'https://www.youtube.com/watch?v=WrT6tQzmSTE', 'vision_cap': ['a box is shown with a woman and man standing nearby.', 'a man opens a brown box that he is holding while his woman looks on.', 'a man is giving instruction on how to unboxing an item for a recipe.', 'the man is showing the lady how much she like the pizza.', 'a person is standing in front of box'], 'audio_cap': ['a dog is being measured in a museum.', 'sound is being measured.', 'someone is giving instructions.', 'people are talking about a dog in a shop.', 'sound is being measured.'], 'subtitle': 'I know theres an actual shipping label which is great to seal your box seal, your box, no thats, great yeah, wonderful, even I dont even have to get tape out.', 'vast_cap': \"The man is showing the lady how much she likes the pizza, while people are talking about a dog in a shop, and the speech subtitle mentions an actual shipping label that is great to seal your box, and the speaker is saying that it's wonderful and doesn't even need to use t\"}\n",
      "{'clip_id': 'g_Fm2yr3lTo.17', 'clip_span': ['00:03:10.080', '00:03:28.859'], 'url': 'https://www.youtube.com/watch?v=g_Fm2yr3lTo', 'vision_cap': ['a person standing on an open field with a person pointing to something', 'a person in grassy area pointing to something and talking.', 'a man shows something to the audience while he points to the green grass and tall grass.', 'a young boy points to a field that is in the middle of a field of flowers.', 'a man is talking through the field of wildflowers and talking to the cameraman.'], 'audio_cap': ['someone is speaking.', 'a person is speaking in a hospital.', 'someone is speaking.', 'sounds are recorded.', 'male voice tells about a lost project.'], 'subtitle': 'In most cases, whenever you get to local parks, however, things can get very, very murky and just make sure that youre always getting permission first before harvesting on any land that isnt yours, thats, the best rule of thumb and youll avoid all legal problems by making sure you always have permission.', 'vast_cap': 'A man is talking through a field of wildflowers, talking to the cameraman, and advising to always get permission before harvesting on any land.'}\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "with open(\"test.json\", 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    for i in data:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duytran/mambaforge/envs/vividbot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['clip_id', 'vision_cap', 'audio_cap', 'url', 'vast_cap', 'subtitle', 'clip_span'],\n",
      "    num_rows: 11\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"json\", data_files=[\"test.json\"])\n",
    "print(data[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'googletrans'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogletrans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Translator\n\u001b[1;32m      2\u001b[0m translator \u001b[38;5;241m=\u001b[39m Translator()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# translate text\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'googletrans'"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "\n",
    "# translate text\n",
    "text = \"a man is using a spoon to scoop something out of a pan that is sitting on top of a pan.\"\n",
    "dest_text = translator.translate(text, dest='vi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['một người đàn ông đang dùng thìa để múc thứ gì đó ra khỏi cái chảo đặt trên chảo.', 'đầu bếp đổ nguyên liệu lên khay rồi thêm một số thực phẩm xanh vào.', 'một người đang dùng chai màu xanh lá cây để đựng thứ gì đó và khuấy nó.', 'một người đổ nước sốt vào tay mình lên một loại thức ăn nào đó', 'một người đang đổ thức ăn vào khay chảo rồi trộn']\n"
     ]
    }
   ],
   "source": [
    "temp = ['a man is using a spoon to scoop something out of a pan that is sitting on top of a pan.', 'a chef pours ingredients on a tray and then adds some green food.', 'a person is using a green bottle on something and is stirring it.', 'an individual pours a sauce in his hand onto some type of food', 'a person is pouring food into a tray of pans and then mixing it']\n",
    "dest_temp = translator.translate(temp, dest='vi')\n",
    "print([i.text for i in dest_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(translator\u001b[38;5;241m.\u001b[39mtranslate(item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvision_cap\u001b[39m\u001b[38;5;124m\"\u001b[39m], dest\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvi\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "for item in data[\"train\"]:\n",
    "    print(translator.translate(item[\"vision_cap\"], dest='vi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatGroq(temperature=0, groq_api_key=\"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\", model_name=\"mixtral-8x7b-32768\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The sentence \"A man is using a spoon to scoop something out of a pan that is sitting on top of another pan\" can be translated to Vietnamese as \"Một người đàn ông đang sử dụng một muỗng để lấy một số thứ ra khỏi một chảo đang đứng trên một chảo khác\".', response_metadata={'token_usage': {'completion_time': 0.186, 'completion_tokens': 107, 'prompt_time': 0.009, 'prompt_tokens': 43, 'queue_time': None, 'total_time': 0.195, 'total_tokens': 150}, 'model_name': 'mixtral-8x7b-32768', 'system_fingerprint': 'fp_c5f20b5bb1', 'finish_reason': 'stop', 'logprobs': None}, id='run-1535403c-775b-4d85-85e6-1e94b15aa98a-0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = \"You are a helpful assistant.\"\n",
    "human = \"{text}\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "chain = prompt | chat\n",
    "chain.invoke({\"text\": \"dịch \\{a man is using a spoon to scoop something out of a pan that is sitting on top of a pan.\\}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duytran/.cache/huggingface/modules/transformers_modules/vinai/PhoGPT-4B-Chat/116013fa63f8c4025739487e1cbff65b7375bbe2/attention.py:87: UserWarning: Propagating key_padding_mask to the attention module and applying it within the attention module can cause unnecessary computation/memory usage. Consider integrating into attn_bias once and passing that to each attention module instead.\n",
      "  warnings.warn('Propagating key_padding_mask to the attention module ' + 'and applying it within the attention module can cause ' + 'unnecessary computation/memory usage. Consider integrating ' + 'into attn_bias once and passing that to each attention ' + 'module instead.')\n"
     ]
    }
   ],
   "source": [
    "# coding: utf8\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"vinai/PhoGPT-4B-Chat\"  \n",
    "\n",
    "config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)  \n",
    "config.init_device = \"cuda\"\n",
    "#config.attn_config['attn_impl'] = 'flash' # If installed: this will use either Flash Attention V1 or V2 depending on what is installed\n",
    "\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_path, config=config, torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "# If your GPU does not support bfloat16:\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, config=config, torch_dtype=torch.float16, trust_remote_code=True)\n",
    "model.eval()  \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)  \n",
    "\n",
    "PROMPT_TEMPLATE = \"### Câu hỏi: {instruction}\\n### Trả lời:\"  \n",
    "\n",
    "# Some instruction examples\n",
    "# instruction = \"Viết bài văn nghị luận xã hội về {topic}\"\n",
    "# instruction = \"Viết bản mô tả công việc cho vị trí {job_title}\"\n",
    "# instruction = \"Sửa lỗi chính tả:\\n{sentence_or_paragraph}\"\n",
    "# instruction = \"Dựa vào văn bản sau đây:\\n{text}\\nHãy trả lời câu hỏi: {question}\"\n",
    "# instruction = \"Tóm tắt văn bản:\\n{text}\"\n",
    "\n",
    "instruction = \"dịch \\\"A man is talking through a field of wildflowers, talking to the cameraman, and advising to always get permission before harvesting on any land.\\\" sang tiếng Việt\"\n",
    "# instruction = \"Sửa lỗi chính tả:\\nTriệt phá băng nhóm kướp ô tô, sử dụng \\\"vũ khí nóng\\\"\"\n",
    "\n",
    "input_prompt = PROMPT_TEMPLATE.format_map({\"instruction\": instruction})  \n",
    "\n",
    "input_ids = tokenizer(input_prompt, return_tensors=\"pt\")  \n",
    "\n",
    "outputs = model.generate(  \n",
    "    inputs=input_ids[\"input_ids\"].to(\"cuda\"),  \n",
    "    attention_mask=input_ids[\"attention_mask\"].to(\"cuda\"),  \n",
    "    do_sample=True,  \n",
    "    temperature=1.0,  \n",
    "    top_k=50,  \n",
    "    top_p=0.9,  \n",
    "    max_new_tokens=1024,  \n",
    "    eos_token_id=tokenizer.eos_token_id,  \n",
    "    pad_token_id=tokenizer.pad_token_id  \n",
    ")  \n",
    "\n",
    "response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]  \n",
    "response = response.split(\"### Trả lời:\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Người đàn ông đang đi qua một cánh đồng hoa dại, nói chuyện với người quay phim, và luôn nhắc nhở phải được sự cho phép trước khi hái bất cứ loại hoa nào.\"\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"dịch \\\"A man is talking through a field of wildflowers, talking to the cameraman, and advising to always get permission before harvesting on any land.\\\" sang tiếng Việt\"\n",
    "# instruction = \"Sửa lỗi chính tả:\\nTriệt phá băng nhóm kướp ô tô, sử dụng \\\"vũ khí nóng\\\"\"\n",
    "\n",
    "input_prompt = PROMPT_TEMPLATE.format_map({\"instruction\": instruction})  \n",
    "\n",
    "input_ids = tokenizer(input_prompt, return_tensors=\"pt\")  \n",
    "\n",
    "outputs = model.generate(  \n",
    "    inputs=input_ids[\"input_ids\"].to(\"cuda\"),  \n",
    "    attention_mask=input_ids[\"attention_mask\"].to(\"cuda\"),  \n",
    "    do_sample=True,  \n",
    "    temperature=1.0,  \n",
    "    top_k=50,  \n",
    "    top_p=0.9,  \n",
    "    max_new_tokens=1024,  \n",
    "    eos_token_id=tokenizer.eos_token_id,  \n",
    "    pad_token_id=tokenizer.pad_token_id  \n",
    ")  \n",
    "\n",
    "response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]  \n",
    "response = response.split(\"### Trả lời:\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duytran/miniconda3/envs/vividbot/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"json\", data_files=[\"/home/duytran/Downloads/vast27m_annotations/annotations.json\"], streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(iter(data['train'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 2.68k/2.68k [00:00<00:00, 4.80MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '004539375', 'conversations': [{'from': 'human', 'value': 'Render a clear and concise summary of the photo.\\n<image>'}, {'from': 'gpt', 'value': 'select luxury furniture 3 - inch gel memory foam mattress topper'}], 'image': '00453/004539375.jpg'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"liuhaotian/LLaVA-Pretrain\", streaming=True)\n",
    "print(next(iter(dataset['train'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, login\n",
    "# hugging face authen key\n",
    "login(token=\"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\")\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"/home/duytran/Downloads/vast27m_annotations/annotations.json\",\n",
    "    path_in_repo=\"vast27_enannotations.json\",\n",
    "    repo_id=\"Vividbot/vast27_en\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# If the dataset is gated/private, make sure you have run huggingface-cli login\n",
    "dataset = load_dataset(\"Vividbot/vast27_en\", streaming=True)\n",
    "print(next(iter(dataset['train'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duytran/miniconda3/envs/vividbot/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"json\", data_files=[\"/home/duytran/Desktop/ViVidBot/data/result.json\"], streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data[\"train\"]:\n",
    "    print(i[\"vast_cap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ijson\n",
    "import json\n",
    "\n",
    "path = \"/home/duytran/Downloads/vast27m_annotations/annotations.json\"\n",
    "\n",
    "# save first 1 million items\n",
    "result = open(\"result.json\", \"w\")\n",
    "with open(path) as f:\n",
    "    for i, item in enumerate(ijson.items(f, \"item\")):\n",
    "        if i > 1000000:\n",
    "            break\n",
    "        result.write(json.dumps(item) + \"\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duytran/miniconda3/envs/vividbot/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'video', 'conversations'],\n",
      "    num_rows: 702971\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "path = \"/home/duytran/Desktop/ViVidBot/data/chat.json\"\n",
    "\n",
    "data = load_dataset(\"json\", data_files=[path])\n",
    "\n",
    "print(data[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'from': 'human', 'value': 'Write a terse but informative summary of the following video clip.\\n<video>'}\n"
     ]
    }
   ],
   "source": [
    "for i in data[\"train\"]:\n",
    "    print(i[\"conversations\"][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "human_collect = []\n",
    "\n",
    "for item in data[\"train\"]:\n",
    "    if item[\"conversations\"][0][\"value\"] not in human_collect:\n",
    "        human_collect.append(item[\"conversations\"][0][\"value\"])\n",
    "\n",
    "print(len(human_collect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a terse but informative summary of the following video clip.\n",
      "<video>\n",
      "Relay a brief, clear account of the video shown.\n",
      "<video>\n",
      "Offer a succinct explanation of the footage presented.\n",
      "<video>\n",
      "Render a clear and concise summary of the video below.\n",
      "<video>\n",
      "Present a compact description of the clip's key features.\n",
      "<video>\n",
      "Share a concise interpretation of the video provided.\n",
      "<video>\n",
      "Provide a brief description of the given video clip.\n",
      "<video>\n",
      "Create a compact narrative representing the video presented.\n",
      "<video>\n",
      "Summarize the visual content of the following video.\n",
      "<video>\n",
      "Give a short and clear explanation of the subsequent video clip.\n",
      "<video>\n",
      "Describe the following video concisely.\n",
      "<video>\n"
     ]
    }
   ],
   "source": [
    "for i in human_collect:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to txt\n",
    "with open(\"human.txt\", \"w\") as f:\n",
    "    for item in human_collect:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duytran/miniconda3/envs/vividbot/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "safety_settings = [\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "]\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyDexs4YZqNvy6ij_qryTMaz3DyybH0pFKw\")\n",
    "model = genai.GenerativeModel('gemini-pro', safety_settings=safety_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['clip_id', 'clip_span', 'url', 'vision_cap', 'audio_cap', 'subtitle', 'vast_cap'],\n",
      "    num_rows: 2000001\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"json\", data_files=[\"/home/duytran/Desktop/ViVidBot/data/Vast2M.json\"])\n",
    "\n",
    "print(data[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data[\"train\"].select(range(1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'new_vast': '<a>Một người đàn ông đang dùng thìa để vớt thứ gì đó ra khỏi chảo trong khi nói về cách công nghệ giúp hiển thị vị trí trên bản đồ và tránh bị đánh cắp.</a>'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "test = open(\"temp.json\", \"w\")\n",
    "result_all = []\n",
    "for i in range(1000):\n",
    "    result = {\"new_vast\": \"\"}\n",
    "    input = data[\"train\"][i][\"vast_cap\"]\n",
    "    response = model.generate_content(f\"\"\"translate \\\"{input}\\\" from English to Vietnamese with natural tone and without grammar incorrect, just return as format \n",
    "   <a>content translation<a>\"\"\")\n",
    "    result[\"new_vast\"] = response.text\n",
    "    print(result)\n",
    "    result_all.append(result)\n",
    "    break\n",
    "test.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_fn(batch):\n",
    "    result = []\n",
    "    for item in batch[\"vast_cap\"]:\n",
    "        response = model.generate_content(f\"translate \\\"{item}\\\" from English to Vietnamese with natural tone and without grammar incorrect, just return the result of translation\")\n",
    "        result.append(response.text)\n",
    "    batch[\"vast_cap\"] = result\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=16):   0%|          | 0/1000 [02:34<?, ? examples/s]\n"
     ]
    }
   ],
   "source": [
    "new_data.map(map_fn, batched=True, batch_size=100, num_proc=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnew_data\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vividbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
