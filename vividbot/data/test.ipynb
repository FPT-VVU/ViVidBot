{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count (x):\n",
    "    return len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open(\"test.json\", 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    for i in data:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"json\", data_files=[\"/home/duytran/Downloads/vividbot_data/Vast2M.json\"])\n",
    "print(data[\"train\"].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "\n",
    "# translate text\n",
    "text = \"a man is using a spoon to scoop something out of a pan that is sitting on top of a pan.\"\n",
    "dest_text = translator.translate(text, dest='vi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "from yt_dlp.utils import download_range_func\n",
    "start =302\n",
    "end = 400\n",
    "yt_opts = { 'format': 'best[ext=mp4]', \n",
    "           'download_ranges': download_range_func(None, [(start, end)]), \n",
    "           'force_keyframes_at_cuts': True, \n",
    "           \"outtmpl\": \"/home/duytran/Downloads/a32f1Dyd2GM.%(ext)s\"}\n",
    "url = \"https://www.youtube.com/watch?v=a32f1Dyd2GM\"\n",
    "with yt_dlp.YoutubeDL(yt_opts) as ydl:\n",
    "  ydl.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset(\"json\", data_files=\"/home/duytran/Desktop/ViVidBot/Vast2M_vi.json\")\n",
    "for i in data[\"train\"]:\n",
    "    print(i[\"conversation\"][0][\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ['a man is using a spoon to scoop something out of a pan that is sitting on top of a pan.', 'a chef pours ingredients on a tray and then adds some green food.', 'a person is using a green bottle on something and is stirring it.', 'an individual pours a sauce in his hand onto some type of food', 'a person is pouring food into a tray of pans and then mixing it']\n",
    "dest_temp = translator.translate(temp, dest='vi')\n",
    "print([i.text for i in dest_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in data[\"train\"]:\n",
    "    print(translator.translate(item[\"vision_cap\"], dest='vi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatGroq(temperature=0, groq_api_key=\"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\", model_name=\"mixtral-8x7b-32768\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"You are a helpful assistant.\"\n",
    "human = \"{text}\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "chain = prompt | chat\n",
    "chain.invoke({\"text\": \"dịch \\{a man is using a spoon to scoop something out of a pan that is sitting on top of a pan.\\}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf8\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"vinai/PhoGPT-4B-Chat\"  \n",
    "\n",
    "config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)  \n",
    "config.init_device = \"cuda\"\n",
    "#config.attn_config['attn_impl'] = 'flash' # If installed: this will use either Flash Attention V1 or V2 depending on what is installed\n",
    "\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_path, config=config, torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "# If your GPU does not support bfloat16:\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, config=config, torch_dtype=torch.float16, trust_remote_code=True)\n",
    "model.eval()  \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)  \n",
    "\n",
    "PROMPT_TEMPLATE = \"### Câu hỏi: {instruction}\\n### Trả lời:\"  \n",
    "\n",
    "# Some instruction examples\n",
    "# instruction = \"Viết bài văn nghị luận xã hội về {topic}\"\n",
    "# instruction = \"Viết bản mô tả công việc cho vị trí {job_title}\"\n",
    "# instruction = \"Sửa lỗi chính tả:\\n{sentence_or_paragraph}\"\n",
    "# instruction = \"Dựa vào văn bản sau đây:\\n{text}\\nHãy trả lời câu hỏi: {question}\"\n",
    "# instruction = \"Tóm tắt văn bản:\\n{text}\"\n",
    "\n",
    "instruction = \"dịch \\\"A man is talking through a field of wildflowers, talking to the cameraman, and advising to always get permission before harvesting on any land.\\\" sang tiếng Việt\"\n",
    "# instruction = \"Sửa lỗi chính tả:\\nTriệt phá băng nhóm kướp ô tô, sử dụng \\\"vũ khí nóng\\\"\"\n",
    "\n",
    "input_prompt = PROMPT_TEMPLATE.format_map({\"instruction\": instruction})  \n",
    "\n",
    "input_ids = tokenizer(input_prompt, return_tensors=\"pt\")  \n",
    "\n",
    "outputs = model.generate(  \n",
    "    inputs=input_ids[\"input_ids\"].to(\"cuda\"),  \n",
    "    attention_mask=input_ids[\"attention_mask\"].to(\"cuda\"),  \n",
    "    do_sample=True,  \n",
    "    temperature=1.0,  \n",
    "    top_k=50,  \n",
    "    top_p=0.9,  \n",
    "    max_new_tokens=1024,  \n",
    "    eos_token_id=tokenizer.eos_token_id,  \n",
    "    pad_token_id=tokenizer.pad_token_id  \n",
    ")  \n",
    "\n",
    "response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]  \n",
    "response = response.split(\"### Trả lời:\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"dịch \\\"A man is talking through a field of wildflowers, talking to the cameraman, and advising to always get permission before harvesting on any land.\\\" sang tiếng Việt\"\n",
    "# instruction = \"Sửa lỗi chính tả:\\nTriệt phá băng nhóm kướp ô tô, sử dụng \\\"vũ khí nóng\\\"\"\n",
    "\n",
    "input_prompt = PROMPT_TEMPLATE.format_map({\"instruction\": instruction})  \n",
    "\n",
    "input_ids = tokenizer(input_prompt, return_tensors=\"pt\")  \n",
    "\n",
    "outputs = model.generate(  \n",
    "    inputs=input_ids[\"input_ids\"].to(\"cuda\"),  \n",
    "    attention_mask=input_ids[\"attention_mask\"].to(\"cuda\"),  \n",
    "    do_sample=True,  \n",
    "    temperature=1.0,  \n",
    "    top_k=50,  \n",
    "    top_p=0.9,  \n",
    "    max_new_tokens=1024,  \n",
    "    eos_token_id=tokenizer.eos_token_id,  \n",
    "    pad_token_id=tokenizer.pad_token_id  \n",
    ")  \n",
    "\n",
    "response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]  \n",
    "response = response.split(\"### Trả lời:\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"json\", data_files=[\"/home/duytran/Downloads/vast27m_annotations/annotations.json\"], streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(iter(data['train'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"liuhaotian/LLaVA-Pretrain\", streaming=True)\n",
    "print(next(iter(dataset['train'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, login\n",
    "# hugging face authen key\n",
    "login(token=\"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\")\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"/home/duytran/Downloads/vast27m_annotations/annotations.json\",\n",
    "    path_in_repo=\"vast27_enannotations.json\",\n",
    "    repo_id=\"Vividbot/vast27_en\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# If the dataset is gated/private, make sure you have run huggingface-cli login\n",
    "dataset = load_dataset(\"Vividbot/vast27_en\", streaming=True)\n",
    "print(next(iter(dataset['train'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"json\", data_files=[\"/home/duytran/Desktop/ViVidBot/data/result.json\"], streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data[\"train\"]:\n",
    "    print(i[\"vast_cap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ijson\n",
    "import json\n",
    "\n",
    "path = \"/home/duytran/Downloads/vast27m_annotations/annotations.json\"\n",
    "\n",
    "# save first 1 million items\n",
    "result = open(\"result.json\", \"w\")\n",
    "with open(path) as f:\n",
    "    for i, item in enumerate(ijson.items(f, \"item\")):\n",
    "        if i > 1000000:\n",
    "            break\n",
    "        result.write(json.dumps(item) + \"\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "path = \"/home/duytran/Desktop/ViVidBot/data/chat.json\"\n",
    "\n",
    "data = load_dataset(\"json\", data_files=[path])\n",
    "\n",
    "print(data[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data[\"train\"]:\n",
    "    print(i[\"conversations\"][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_collect = []\n",
    "\n",
    "for item in data[\"train\"]:\n",
    "    if item[\"conversations\"][0][\"value\"] not in human_collect:\n",
    "        human_collect.append(item[\"conversations\"][0][\"value\"])\n",
    "\n",
    "print(len(human_collect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in human_collect:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to txt\n",
    "with open(\"human.txt\", \"w\") as f:\n",
    "    for item in human_collect:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "safety_settings = [\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "]\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyDexs4YZqNvy6ij_qryTMaz3DyybH0pFKw\")\n",
    "model = genai.GenerativeModel('gemini-pro', safety_settings=safety_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"json\", data_files=[\"/home/duytran/Desktop/ViVidBot/data/Vast2M.json\"])\n",
    "\n",
    "print(data[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data[\"train\"].select(range(1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "test = open(\"temp.json\", \"w\")\n",
    "result_all = []\n",
    "for i in range(1000):\n",
    "    result = {\"new_vast\": \"\"}\n",
    "    input = data[\"train\"][i][\"vast_cap\"]\n",
    "    response = model.generate_content(f\"\"\"translate \\\"{input}\\\" from English to Vietnamese with natural tone and without grammar incorrect, just return as format \n",
    "   <a>content translation<a>\"\"\")\n",
    "    result[\"new_vast\"] = response.text\n",
    "    print(result)\n",
    "    result_all.append(result)\n",
    "    break\n",
    "test.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_fn(batch):\n",
    "    result = []\n",
    "    for item in batch[\"vast_cap\"]:\n",
    "        response = model.generate_content(f\"translate \\\"{item}\\\" from English to Vietnamese with natural tone and without grammar incorrect, just return the result of translation\")\n",
    "        result.append(response.text)\n",
    "    batch[\"vast_cap\"] = result\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.map(map_fn, batched=True, batch_size=100, num_proc=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=OXi4T58PwdM\"\n",
    "\n",
    "# times in seconds\n",
    "start = \"00:10:00\"\n",
    "end = \"00:15:00\"\n",
    "\n",
    "ffmpeg_args = {\n",
    "  # - Don't forget the _i after \"ffmpeg\"; this puts the arguments before ffmpeg's `-i` argument,\n",
    "  #   thus short-circuiting the download itself. Fail to do that,\n",
    "  #   and you might as well skip ffmpeg for the download and trim in post-processing.\n",
    "  # - Note that the arguments are pre-parsed into a list, like you'd pass to `subprocess.run`.\n",
    "  \"ffmpeg_i\": [\"-ss\", str(start), \"-to\", str(end)]  \n",
    "}\n",
    "\n",
    "opts = {\n",
    "  \"external_downloader\": \"ffmpeg\",\n",
    "  \"external_downloader_args\": ffmpeg_args,\n",
    "  # though not required, I'm including the subtitles options here for a reason; see below\n",
    "  \"writesubtitles\": False,\n",
    "  \"writeautomaticsub\": False,\n",
    "  # to suppress ffmpeg's stdout output\n",
    "  \"quiet\": True,\n",
    "}\n",
    "\n",
    "with yt_dlp.YoutubeDL(opts) as ydl:\n",
    "  ydl.download(url)\n",
    "  \n",
    "  # If you want WebVTT captions, yt-dlp will fail to download them if you're using ffmpeg.\n",
    "  # This isn't ffmpeg's fault; it's because yt-dlp (as of this writing) forces ffmpeg to use\n",
    "  # the stream copy encoder (look for `args += ['-c', 'copy']` in downloader/external.py).\n",
    "  # yt-dlp hosts their own builds of ffmpeg, and one of them supposedly fixes this problem\n",
    "  # by ignoring certain WebVTT header lines, but why would you want to install a custom build\n",
    "  # to download a less informative version of the caption files?\n",
    "  # Anyway, we can't get around this with any other options that I've found, \n",
    "  # so we'll run a second download to get captions.\n",
    "  \n",
    "  # Note that you can create a new YouTubeDL instance with a new options dictionary, but the\n",
    "  # constructor is a bit expensive, so I'm including an example of reusing a built instance\n",
    "  # for kicks. This dictionary tweaking is likely best separated out into its own function.\n",
    "  opts = {\n",
    "    **ydl.params,\n",
    "    \"external_downloader\": \"native\",\n",
    "    \"external_downloader_args\": {},\n",
    "    \"writesubtitles\": True,\n",
    "    # if you also want automatically generated captions/subtitles\n",
    "    \"writeautomaticsub\": True,\n",
    "    # so we only get the captions and don't download the (whole) video again\n",
    "    \"skip_download\": True,\n",
    "  }\n",
    "  ydl.params = opts\n",
    "  ydl.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duytran/miniconda3/envs/vividbot/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000001\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset(\"json\", data_files=\"/home/duytran/Downloads/vividbot_data/Vast2M.json\")\n",
    "\n",
    "print(len(data[\"train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['clip_id', 'clip_span', 'url', 'vision_cap', 'audio_cap', 'subtitle', 'vast_cap'])\n"
     ]
    }
   ],
   "source": [
    "print(data[\"train\"].features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 62501/62501 [00:00<00:00, 970807.78 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1031007.63 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1055844.43 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1049692.87 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1079959.63 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1110991.50 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1112306.73 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1099814.14 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1099555.81 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1089289.28 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1081041.85 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1092694.64 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1094556.11 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1087978.22 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1074351.85 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1066163.43 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 887766.06 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1114965.51 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1096272.63 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1073872.13 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1083732.28 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1075824.48 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1088913.72 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1090871.26 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1094757.24 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1039828.96 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1059248.99 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1092977.10 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1091202.74 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1077597.87 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1081411.99 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 62500/62500 [00:00<00:00, 1078174.03 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# devide dataset into num chunks\n",
    "num_shards = 32\n",
    "for shard_idx in range(num_shards):\n",
    "    shard = data[\"train\"].shard(num_shards=num_shards, index=shard_idx, contiguous=True)\n",
    "    shard.save_to_disk(f\"/home/duytran/Downloads/cache_dir/shard_{shard_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "shard_0 = load_from_disk(f\"/home/duytran/Downloads/cache_dir/result/shard_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '004539375', 'image': '00453/004539375.jpg', 'conversations': [{'from': 'human', 'value': 'Hãy cho biết tóm lược nhanh về nội dung chính của video.\\\\n>video>\\n<video>'}, {'from': 'gpt', 'value': 'chọn đồ nội thất sang trọng 3 - inch gel nệm mút topper'}]}\n",
      "{'id': '002239345', 'image': '00223/002239345.jpg', 'conversations': [{'from': 'human', 'value': 'Kể lại nội dung của video clip một cách ngắn gọn và rõ ràng.\\n<video>'}, {'from': 'gpt', 'value': 'một chiếc đồng hồ màu xám với dây đeo kiểu quân đội'}]}\n",
      "{'id': '005947502', 'image': '00594/005947502.jpg', 'conversations': [{'from': 'human', 'value': 'Giải nghĩa nhanh video này để mình hiểu.\\n<video>'}, {'from': 'gpt', 'value': 'hình ảnh rồng diều bay trên bầu trời xanh'}]}\n",
      "{'id': '005116462', 'image': '00511/005116462.jpg', 'conversations': [{'from': 'human', 'value': 'Cung cấp mô tả ngắn gọn về video clip được đưa ra.\\n<video>'}, {'from': 'gpt', 'value': '$ 10 - Váy mini in hình giá rẻ dễ thương - Áo dài tay ngắn in hoa kiểu nông dân kaki sọc nhiều màu'}]}\n",
      "{'id': '002017886', 'image': '00201/002017886.jpg', 'conversations': [{'from': 'human', 'value': 'Nêu bật những điểm quan trọng của video clip trong vài câu.\\n<video>'}, {'from': 'gpt', 'value': 'thực tế tăng cường sử dụng dấu aruco trong opencv'}]}\n",
      "{'id': '001819539', 'image': '00181/001819539.jpg', 'conversations': [{'from': 'human', 'value': 'Cho mình xin vài ý tóm tắt về video này để nắm.\\n<video>'}, {'from': 'gpt', 'value': 'một đôi bốt trẻ em có hình đôi giày dệt kim'}]}\n",
      "{'id': '002838027', 'image': '00283/002838027.jpg', 'conversations': [{'from': 'human', 'value': 'Mô tả ngắn gọn về video sau.\\n<video>'}, {'from': 'gpt', 'value': 'clip nghệ thuật màu nước hoa hoa hồng viền hoa hồng'}]}\n",
      "{'id': '000406392', 'image': '00040/000406392.jpg', 'conversations': [{'from': 'human', 'value': 'Mình cần nắm được nội dung cơ bản của video, bạn có thể tóm tắt giúp không?\\n<video>'}, {'from': 'gpt', 'value': 'nữ hoàng thần thánh trong chiếc mặt nạ in canvas cầu kỳ có khuôn mặt và bàn tay của một người phụ nữ có mái tóc đỏ'}]}\n",
      "{'id': '006288475', 'image': '00628/006288475.jpg', 'conversations': [{'from': 'human', 'value': 'Bạn có thể cho tôi biết video này nói về cái gì không?\\n<video>'}, {'from': 'gpt', 'value': 'Ảnh chụp từ trên không của Paris vào ban đêm từ máy bay'}]}\n",
      "{'id': '000075539', 'image': '00007/000075539.jpg', 'conversations': [{'from': 'human', 'value': 'Nhìn vào video, bạn có thể hiểu được nội dung chính không? Hãy cho mình biết nhé.\\n<video>'}, {'from': 'gpt', 'value': 'giày nike air trainer màu nâu sa mạc và đen'}]}\n",
      "{'id': '001649122', 'image': '00164/001649122.jpg', 'conversations': [{'from': 'human', 'value': 'Tóm tắt nội dung của video sau.\\n<video>'}, {'from': 'gpt', 'value': 'một hình minh họa của một DJ trong đám đông với dòng chữ so dop'}]}\n",
      "{'id': '002326944', 'image': '00232/002326944.jpg', 'conversations': [{'from': 'human', 'value': 'Xem video xong, bạn có thể chia sẻ ý chính không?\\n<video>'}, {'from': 'gpt', 'value': 'Mặt bằng nhà kiểu biệt thự, 1 phòng ngủ'}]}\n",
      "{'id': '000093116', 'image': '00009/000093116.jpg', 'conversations': [{'from': 'human', 'value': 'Nhìn vào video, bạn có thể hiểu được nội dung chính không? Hãy cho mình biết nhé.\\n<video>'}, {'from': 'gpt', 'value': 'một con mèo nhìn lại ngồi trên một tảng đá ở đại dương kỳ nghỉ & du lịch bãi biển mùa hè động vật đại dương động vật cưng con chó'}]}\n",
      "{'id': '000951660', 'image': '00095/000951660.jpg', 'conversations': [{'from': 'human', 'value': 'Bạn có thể cho tôi biết video này nói về cái gì không?\\n<video>'}, {'from': 'gpt', 'value': 'một thùng đồ chơi nhỏ có in hình gấu trúc'}]}\n",
      "{'id': '006366709', 'image': '00636/006366709.jpg', 'conversations': [{'from': 'human', 'value': 'Mô tả ngắn gọn về video sau.\\n<video>'}, {'from': 'gpt', 'value': 'doanh nhân tại bàn hội nghị, với dòng chữ cho biết lý do tại sao các nhà quản lý thông minh không tổ chức các cuộc họp bán hàng'}]}\n",
      "{'id': '000205111', 'image': '00020/000205111.jpg', 'conversations': [{'from': 'human', 'value': 'Xem video xong, bạn có thể chia sẻ ý chính không?\\n<video>'}, {'from': 'gpt', 'value': 'chương trình hoạt hình hạt đậu phộng, với một cô gái và một người đàn ông giơ cao một tấm biển ghi rằng cô ấy'}]}\n",
      "{'id': '003062571', 'image': '00306/003062571.jpg', 'conversations': [{'from': 'human', 'value': 'Nhìn vào video, bạn có thể hiểu được nội dung chính không? Hãy cho mình biết nhé.\\n<video>'}, {'from': 'gpt', 'value': 'ốp lưng anker cho jbl boom 2'}]}\n",
      "{'id': '005531752', 'image': '00553/005531752.jpg', 'conversations': [{'from': 'human', 'value': 'Mình cần nắm được nội dung cơ bản của video, bạn có thể tóm tắt giúp không?\\n<video>'}, {'from': 'gpt', 'value': 'gói yên trước được gắn vào yên xe đạp'}]}\n",
      "{'id': '005389063', 'image': '00538/005389063.jpg', 'conversations': [{'from': 'human', 'value': 'Giải thích ngắn gọn về những gì được trình chiếu trong video.\\n<video>'}, {'from': 'gpt', 'value': 'Elisabeth Henning'}]}\n",
      "{'id': '003713357', 'image': '00371/003713357.jpg', 'conversations': [{'from': 'human', 'value': 'Bằng vài lời, phác họa nội dung của video dưới đây.\\n<video>'}, {'from': 'gpt', 'value': 'một nhóm người trên một chiếc bè bơm hơi, trên dòng sông nước trắng xóa với sóng vỗ'}]}\n",
      "{'id': '001489285', 'image': '00148/001489285.jpg', 'conversations': [{'from': 'human', 'value': 'Cung cấp mô tả ngắn gọn về video clip được đưa ra.\\n<video>'}, {'from': 'gpt', 'value': 'một nón giao thông màu cam với đèn nhấp nháy màu đỏ'}]}\n",
      "{'id': '003569527', 'image': '00356/003569527.jpg', 'conversations': [{'from': 'human', 'value': 'Cho mình xin vài ý tóm tắt về video này để nắm.\\n<video>'}, {'from': 'gpt', 'value': 'tính toán cho pca'}]}\n",
      "{'id': '000082148', 'image': '00008/000082148.jpg', 'conversations': [{'from': 'human', 'value': 'Bạn có thể cho mình biết video này đang diễn ra sự kiện gì không?\\n<video>'}, {'from': 'gpt', 'value': 'lời chúc giáng sinh với vòng hoa và món trang sức màu đỏ trên nền trắng văn bản giáng sinh scandinavian'}]}\n",
      "{'id': '000956213', 'image': '00095/000956213.jpg', 'conversations': [{'from': 'human', 'value': 'Cho mình xin vài ý tóm tắt về video này để nắm.\\n<video>'}, {'from': 'gpt', 'value': 'tấm thảm mới của nickelodeons'}]}\n",
      "{'id': '006498284', 'image': '00649/006498284.jpg', 'conversations': [{'from': 'human', 'value': 'Tóm tắt ngắn gọn nhưng cung cấp đầy đủ thông tin về video clip này.\\n<video>'}, {'from': 'gpt', 'value': 'gói nhãn dán và nhãn dán máy pha cà phê'}]}\n",
      "{'id': '003618761', 'image': '00361/003618761.jpg', 'conversations': [{'from': 'human', 'value': 'Bạn có thể cho mình biết video này đang diễn ra sự kiện gì không?\\n<video>'}, {'from': 'gpt', 'value': 'Áo tập dài tay 18/21 của nữ Arsenal'}]}\n",
      "{'id': '004564488', 'image': '00456/004564488.jpg', 'conversations': [{'from': 'human', 'value': 'Tóm tắt nội dung của video sau.\\n<video>'}, {'from': 'gpt', 'value': 'một nhóm thiết bị xe máy và mũ bảo hiểm của Anh'}]}\n",
      "{'id': '004398009', 'image': '00439/004398009.jpg', 'conversations': [{'from': 'human', 'value': 'Diễn giải một cách ngắn gọn về video được cung cấp.\\n<video>'}, {'from': 'gpt', 'value': 'một cuốn sách màu đỏ tía với một chiếc thuyền nổi trên mặt nước'}]}\n",
      "{'id': '003472061', 'image': '00347/003472061.jpg', 'conversations': [{'from': 'human', 'value': 'Mình cần nắm được nội dung cơ bản của video, bạn có thể tóm tắt giúp không?\\n<video>'}, {'from': 'gpt', 'value': 'rochelle lovett và joe manda'}]}\n",
      "{'id': '003362053', 'image': '00336/003362053.jpg', 'conversations': [{'from': 'human', 'value': 'Bằng vài lời, phác họa nội dung của video dưới đây.\\n<video>'}, {'from': 'gpt', 'value': 'twit, từ đồng nghĩa với twit, từ đồng nghĩa với twit'}]}\n",
      "{'id': '002972155', 'image': '00297/002972155.jpg', 'conversations': [{'from': 'human', 'value': 'Mô tả ngắn gọn về video sau.\\n<video>'}, {'from': 'gpt', 'value': 'Hội chợ nhà sản xuất trên nền xanh trắng có logo của Hội chợ nhà sản xuất trên đó'}]}\n",
      "{'id': '001745272', 'image': '00174/001745272.jpg', 'conversations': [{'from': 'human', 'value': 'Giải thích ngắn gọn và rõ ràng về video clip phía dưới.\\n<video>'}, {'from': 'gpt', 'value': 'kính râm alpina explorer đen mờ'}]}\n"
     ]
    }
   ],
   "source": [
    "for i in shard_0:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload later\n",
    "from datasets import load_from_disk, concatenate_datasets\n",
    "ds = concatenate_datasets([\n",
    "    load_from_disk(f\"/home/duytran/Downloads/cache_dir/shard_{shard_idx}\")\n",
    "    for shard_idx in range(num_shards)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000001\n"
     ]
    }
   ],
   "source": [
    "print(len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json\n"
     ]
    }
   ],
   "source": [
    "# read number folder in a folder\n",
    "import os\n",
    "path = \"/home/duytran/Downloads/cache_dir.json\"\n",
    "\n",
    "print(path.split(\"/\")[-1].split(\".\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 39] Directory not empty: '/home/duytran/Downloads/cache_dir/temp/shard_0/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/duytran/Downloads/cache_dir/temp/shard_0/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 39] Directory not empty: '/home/duytran/Downloads/cache_dir/temp/shard_0/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.rmdir(\"/home/duytran/Downloads/cache_dir/temp/shard_0/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Specify the path of the folder you want to remove\n",
    "folder_path = '/home/duytran/Downloads/cache_dir/temp/shard_0'\n",
    "\n",
    "# Remove the folder and all its contents\n",
    "shutil.rmtree(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1999983 examples [00:00, 2053978.54 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1000/1000 [00:00<00:00, 1104.39ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1000/1000 [00:00<00:00, 1110.00ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 2/2 [00:50<00:00, 25.02s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Vividbot/vast27_en/commit/4aa235b8b7021c503dedd810aacb052533e9b31a', commit_message='Upload dataset', commit_description='', oid='4aa235b8b7021c503dedd810aacb052533e9b31a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset(\"json\", data_files=\"/home/duytran/Downloads/output_ds/vast2m-vi.json\")\n",
    "data.push_to_hub(\"Vividbot/vast27_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 423/423 [00:00<00:00, 926kB/s]\n",
      "Downloading data: 100%|██████████| 153M/153M [00:14<00:00, 10.8MB/s] \n",
      "Downloading data: 100%|██████████| 153M/153M [00:14<00:00, 10.8MB/s] \n",
      "Generating train split: 100%|██████████| 1999983/1999983 [00:02<00:00, 935160.73 examples/s] \n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# If the dataset is gated/private, make sure you have run huggingface-cli login\n",
    "dataset = load_dataset(\"Vividbot/vast27_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'mmfqMSqa8-Q.10', 'video': 'mmfqMSqa8-Q.10.mp4', 'conversation': [{'from': 'human', 'value': 'Hãy cho biết tóm lược nhanh về nội dung chính của video.\\\\n>video>\\n<video>'}, {'from': 'gpt', 'value': 'Ba cô gái đang nói, và người đàn ông đang nói về trải nghiệm của anh ấy, và họ cảm thấy họ như gia đình đối với anh ấy, và anh ấy yêu bóng chuyền.'}]}\n"
     ]
    }
   ],
   "source": [
    "for i in dataset[\"train\"]:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duytran/miniconda3/envs/vividbot/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vividbot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprocessor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mupload_hf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Uploader\n\u001b[1;32m      3\u001b[0m uploader \u001b[38;5;241m=\u001b[39m Uploader()\n\u001b[1;32m      4\u001b[0m uploader\u001b[38;5;241m.\u001b[39mupload_file(file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/duytran/Downloads/output_video/error/error_shard_1.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m                             repo_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVividbot/vast2m_vi\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m                             path_in_repo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror/error_shard_1.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m                             repo_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m                             overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/ViVidBot/vividbot/data/processor/upload_hf.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HfApi, HfFolder, HfFileSystem\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvividbot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseProcessor\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvividbot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m zip_dir\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mUploader\u001b[39;00m(BaseProcessor):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vividbot'"
     ]
    }
   ],
   "source": [
    "\n",
    "from processor.upload_hf import Uploader\n",
    "\n",
    "uploader = Uploader()\n",
    "uploader.upload_file(file_path=\"/home/duytran/Downloads/output_video/error/error_shard_1.json\",\n",
    "                            repo_id=\"Vividbot/vast2m_vi\",\n",
    "                            path_in_repo=f\"error/error_shard_1.json\",\n",
    "                            repo_type=\"dataset\",\n",
    "                            overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duytran/miniconda3/envs/vividbot/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Creating json from Arrow format: 100%|██████████| 2001/2001 [00:53<00:00, 37.31ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1047563641"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "path_chunk_en = \"/home/duytran/Downloads/output_ds/vast_2m_chunk_en/shard_0.json\"\n",
    "vi_dataset_path = \"/home/duytran/Downloads/output_ds/vast2M_vi.json\"\n",
    "output_dir = \"/home/duytran/Downloads/output_ds/temp\"\n",
    " \n",
    "id = \"G1DRYgjsZTw.63\"\n",
    "# read vi data\n",
    "vi_data = load_dataset(\"json\", data_files=vi_dataset_path)[\"train\"]\n",
    "vi_data = vi_data.to_polars()\n",
    "en_data = load_dataset(\"json\", data_files=path_chunk_en)[\"train\"]\n",
    "en_data = en_data.to_polars()\n",
    "\n",
    "# rename column\n",
    "en_data = en_data.rename({\"clip_id\": \"id\"})\n",
    "\n",
    "new_data = vi_data.join(en_data, on=\"id\", how=\"left\")\n",
    "new_data = Dataset.from_pandas(new_data.to_pandas())\n",
    "\n",
    "# write json file for each \n",
    "new_data.to_json(\n",
    "            output_dir + \"/shard_0_new.json\",\n",
    "            orient=\"records\",\n",
    "            lines=True,\n",
    "            force_ascii=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vividbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
